# Module Reference

> Auto-generated by MyWork AI Doc Generator

**Total modules:** 130

## `examples/cli-task-manager/src/models.py`

Task data models for the CLI Task Manager.

This module defines the core data structures used throughout the application,
following the patterns established by the MyWork framework.

*277 lines*

### class `Priority`(Enum)

Task priority levels.

| Method | Args | Description |
|--------|------|-------------|
| `from_string` | `cls, value` | Create Priority from string value. |

### class `Status`(Enum)

Task completion status.

### class `Task`

A task represents a single todo item with metadata.

This class follows the dataclass pattern for clean serialization
and includes validation and helper methods.

| Method | Args | Description |
|--------|------|-------------|
| `status` | `` | Get the current status of the task. |
| `is_overdue` | `` | Check if the task is overdue. |
| `days_until_due` | `` | Calculate days until due date. Negative if overdue. |
| `complete` | `` | Mark the task as completed. |
| `uncomplete` | `` | Mark the task as not completed. |
| `update_title` | `new_title` | Update the task title with validation. |
| `update_priority` | `new_priority` | Update the task priority. |
| `update_due_date` | `new_due_date` | Update the task due date. |
| `matches_query` | `query, case_sensitive` | Check if task title matches the search query. |
| `to_dict` | `` | Convert task to dictionary for serialization. |
| `from_dict` | `cls, data` | Create task from dictionary (deserialization). |

### class `TaskStats`

Statistics about a collection of tasks.

| Method | Args | Description |
|--------|------|-------------|
| `completion_rate` | `` | Calculate completion percentage. |
| `overdue_rate` | `` | Calculate overdue percentage. |
| `from_tasks` | `cls, tasks` | Calculate statistics from a list of tasks. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `validate_task_data` | `data` | Validate task data and return any validation errors. |

---

## `examples/cli-task-manager/src/storage.py`

Task storage and persistence layer for the CLI Task Manager.

This module handles saving and loading tasks from JSON files,
providing a simple file-based database solution.

*430 lines*

### class `TaskStorage`

File-based storage for tasks using JSON format.

This class provides a simple persistence layer that saves tasks
to a JSON file in the user's home directory or current directory.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `file_path` | Initialize storage with optional custom file path. |
| `get_tasks` | `include_completed` | Retrieve all tasks from storage. |
| `get_task` | `task_id` | Retrieve a single task by ID. |
| `add_task` | `task` | Add a new task to storage. |
| `update_task` | `updated_task` | Update an existing task in storage. |
| `delete_task` | `task_id` | Delete a task from storage. |
| `complete_task` | `task_id` | Mark a task as completed. |
| `uncomplete_task` | `task_id` | Mark a task as not completed. |
| `search_tasks` | `query, case_sensitive` | Search for tasks matching a query string. |
| `get_next_id` | `` | Get the next available task ID. |
| `get_stats` | `` | Get statistics about all tasks. |
| `get_overdue_tasks` | `` | Get all overdue tasks. |
| `get_due_today` | `` | Get all tasks due today. |
| `get_tasks_by_priority` | `priority` | Get all tasks with a specific priority. |
| `clear_completed_tasks` | `` | Remove all completed tasks from storage. |
| `export_to_json` | `export_path` | Export tasks to a different JSON file. |
| `import_from_json` | `import_path, merge` | Import tasks from a JSON file. |
| `get_file_info` | `` | Get information about the storage file. |

---

## `examples/cli-task-manager/src/task_manager.py`

Simple Task Manager CLI - Built with MyWork Framework

A command-line task manager demonstrating GSD development workflow
and CLI best practices.

Usage:
    python task_manager.py add "Task title" [--priority high] [--due 2024-12-31]
    python task_manager.py list [--status pending|completed] [--priority low|normal|high]
    python task_manager.py complete <task_id>
    python task_manager.py delete <task_id>
    python task_manager.py search <query>
    python task_manager.py stats

*352 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `cli` | `ctx, version` | üöÄ Simple Task Manager - Built with MyWork Framework |
| `add` | `title, priority, due` | üìù Add a new task to your list. |
| `list` | `status, priority, overdue` | üìã List your tasks. |
| `complete` | `task_id` | ‚úÖ Mark a task as completed. |
| `delete` | `task_id` | üóëÔ∏è  Delete a task permanently. |
| `search` | `query, case_sensitive` | üîç Search tasks by title. |
| `stats` | `` | üìä Show task statistics. |
| `edit` | `task_id, title, priority, due` | ‚úèÔ∏è  Edit an existing task. |

---

## `projects/ai-dashboard/backend/database/db.py`

*76 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `init_db` | `` | Initialize database and create all tables |
| `get_db` | `` | Dependency for sync database sessions |
| `get_db_session` | `` | Context manager for database sessions |
| `async get_async_db` | `` | Dependency for async database sessions |

---

## `projects/ai-dashboard/backend/database/models.py`

*181 lines*

### class `YouTubeVideo`(Base)

Scraped AI-related YouTube videos

| Method | Args | Description |
|--------|------|-------------|
| `calculate_quality_score` | `` | Calculate video quality score based on engagement metrics |

### class `AINews`(Base)

Aggregated AI news articles

### class `GitHubProject`(Base)

Top open source AI projects from GitHub

| Method | Args | Description |
|--------|------|-------------|
| `calculate_trending_score` | `previous_stars` | Calculate trending score based on stars growth and activity |

### class `YouTubeAutomation`(Base)

YouTube video automation pipeline records

### class `ScraperLog`(Base)

Log of scraper runs for monitoring

---

## `projects/ai-dashboard/backend/main.py`

*463 lines*

### class `VideoResponse`(BaseModel)

### class `NewsResponse`(BaseModel)

### class `ProjectResponse`(BaseModel)

### class `AutomationCreate`(BaseModel)

### class `AutomationUpdate`(BaseModel)

### class `AutomationResponse`(BaseModel)

### class `Config`

### class `Config`

### class `Config`

### class `Config`

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `validate_api_keys` | `` | Validate required API keys on startup |
| `async lifespan` | `app` | Startup and shutdown events |
| `async root` | `` | API root endpoint |
| `async get_videos` | `limit, min_views, db` | Get top AI videos |
| `async trigger_video_scrape` | `db` | Manually trigger YouTube scraper |
| `async get_news` | `limit, source, db` | Get latest AI news |
| `async get_trending_news` | `limit, db` | Get trending AI news |
| `async trigger_news_scrape` | `db` | Manually trigger news aggregator |
| `async get_projects` | `limit, min_stars, db` | Get top AI GitHub projects |
| `async get_trending_projects` | `limit, db` | Get trending AI GitHub projects |
| `async trigger_projects_scrape` | `db` | Manually trigger GitHub scraper |
| `async get_automations` | `status, limit, db` | Get all video automations |
| `async get_automation` | `automation_id, db` | Get a specific automation |
| `async create_automation` | `data, db` | Create a new video automation from prompt |
| `async update_automation` | `automation_id, data, db` | Update a video automation draft |
| `async generate_video` | `automation_id, db` | Generate HeyGen video for automation |
| `async check_video_status` | `automation_id, db` | Check HeyGen video generation status |
| `async approve_automation` | `automation_id, db` | Approve and upload video to YouTube |
| `async get_scheduler_status` | `` | Get scheduler job status |
| `async run_job` | `job_id` | Manually trigger a scheduled job |
| `async get_stats` | `db` | Get dashboard statistics |

---

## `projects/ai-dashboard/backend/scrapers/github_trending.py`

*276 lines*

### class `GitHubTrendingScraper`

Scrapes trending AI/ML projects from GitHub

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `github_token` |  |
| `async scrape_trending` | `db, queries, max_results` | Scrape trending AI projects from GitHub |
| `get_top_projects` | `db, limit, min_stars` | Get top AI projects by stars |
| `get_trending_projects` | `db, limit` | Get trending AI projects by weekly growth |
| `get_recently_updated` | `db, limit, days` | Get recently updated AI projects |

---

## `projects/ai-dashboard/backend/scrapers/news_aggregator.py`

*301 lines*

### class `NewsAggregator`

Aggregates AI news from multiple sources

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `async aggregate_news` | `db, include_rss, include_hackernews, max_items_per_source` | Aggregate AI news from all sources |
| `get_latest_news` | `db, limit, source, days` | Get latest AI news from database |
| `get_trending_news` | `db, limit, days` | Get trending AI news (by score/comments) |
| `async close` | `` | Close HTTP client |

---

## `projects/ai-dashboard/backend/scrapers/youtube_scraper.py`

*333 lines*

### class `YouTubeScraper`

Scrapes top AI-related YouTube videos using Apify

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `apify_api_key` |  |
| `async scrape_videos` | `db, queries, max_results_per_query, published_after_days` | Scrape AI-related videos from YouTube |
| `get_top_videos` | `db, limit, min_views, days` | Get top rated AI videos from database |

---

## `projects/ai-dashboard/backend/scripts/youtube_upload_smoke.py`

YouTube Upload Smoke Test

Safely validate OAuth credentials and optionally upload a local video file.

Usage:
  python3 scripts/youtube_upload_smoke.py --dry-run
  python3 scripts/youtube_upload_smoke.py --video /path/to/video.mp4 --confirm
  python3 scripts/youtube_upload_smoke.py --video /path/to/video.mp4 --thumbnail /path/to/thumb.png --confirm

*142 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `projects/ai-dashboard/backend/services/prompt_optimizer.py`

*166 lines*

### class `VideoScriptSignature`(Signature)

Generate an engaging YouTube video script about an AI topic

### class `ContentEnhancer`(Signature)

Enhance and improve content for better engagement

### class `PromptOptimizer`

Optimizes prompts for YouTube video content generation using DSPy

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `anthropic_api_key` |  |
| `generate_video_content` | `topic, target_audience, video_length` | Generate complete video content from a topic |
| `enhance_content` | `content, content_type, style` | Enhance existing content for better engagement |
| `optimize_prompt` | `user_prompt` | Optimize a user prompt for better AI generation |

---

## `projects/ai-dashboard/backend/services/scheduler_service.py`

*123 lines*

### class `SchedulerService`

Manages scheduled scraping tasks

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `start` | `` | Start the scheduler with all jobs (staggered to avoid load spikes) |
| `stop` | `wait` | Stop the scheduler gracefully |
| `get_job_status` | `` | Get status of all scheduled jobs |
| `async run_job_now` | `job_id` | Manually trigger a job |

---

## `projects/ai-dashboard/backend/services/youtube_automation.py`

*478 lines*

### class `YouTubeAutomationService`

Complete YouTube video automation pipeline:
1. Prompt optimization (DSPy)
2. Script generation (Claude)
3. Video creation (HeyGen)
4. Preview & Edit (User)
5. Upload (YouTube API)

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `anthropic_api_key, heygen_api_key, youtube_api_key` |  |
| `async create_video_draft` | `db, user_prompt, target_audience, video_length` | Create a video draft from user prompt |
| `async generate_heygen_video` | `db, automation_id, avatar_id, voice_id` | Generate video using HeyGen API |
| `async check_heygen_status` | `db, automation_id` | Check HeyGen video generation status |
| `async update_draft` | `db, automation_id, updates` | Update video draft with user edits |
| `async approve_and_upload` | `db, automation_id` | Approve draft and upload to YouTube |
| `get_draft` | `db, automation_id` | Get a video draft by ID |
| `get_all_drafts` | `db, status, limit` | Get all video drafts, optionally filtered by status |
| `async close` | `` | Close HTTP client |

---

## `projects/api-hub/backend/database/db.py`

API Hub Database Configuration

*25 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_db` | `` | Dependency for FastAPI endpoints. |
| `init_db` | `` | Create all tables. |

---

## `projects/api-hub/backend/database/models.py`

API Hub Database Models

*37 lines*

### class `APIKey`(Base)

### class `UsageLog`(Base)

---

## `projects/api-hub/backend/main.py`

API Hub ‚Äî Centralized API Key Manager
FastAPI application entry point.

*219 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `startup` | `` |  |
| `mask_key` | `key` | Show only last 6 characters of a key. |
| `add_key` | `payload, db` | Add a new API key. |
| `list_keys` | `provider, active_only, db` | List all API keys (masked). |
| `get_key` | `key_id, db` | Get a specific API key (masked). |
| `delete_key` | `key_id, db` | Revoke/delete an API key. |
| `deactivate_key` | `key_id, db` | Deactivate a key without deleting it. |
| `activate_key` | `key_id, db` | Re-activate a key. |
| `log_usage` | `key_id, tokens, cost, endpoint, status_code` | Log usage for a key. |
| `get_usage` | `key_id, limit, db` | Get usage stats and recent logs for a key. |
| `dashboard` | `db` | Usage dashboard ‚Äî overview of all keys and providers. |
| `health` | `` |  |
| `root` | `` |  |

---

## `projects/api-hub/backend/schemas.py`

API Hub Pydantic Schemas

*65 lines*

### class `APIKeyCreate`(BaseModel)

### class `APIKeyResponse`(BaseModel)

### class `APIKeyUsage`(BaseModel)

### class `UsageLogResponse`(BaseModel)

### class `DashboardResponse`(BaseModel)

### class `Config`

### class `Config`

---

## `projects/api-hub/tests/test_api.py`

API Hub Tests ‚Äî Full CRUD + Usage + Dashboard

*153 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `test_health` | `` |  |
| `test_root` | `` |  |
| `test_add_key` | `` |  |
| `test_list_keys` | `` |  |
| `test_add_multiple_providers` | `` |  |
| `test_get_single_key` | `` |  |
| `test_get_nonexistent_key` | `` |  |
| `test_log_usage` | `` |  |
| `test_get_usage` | `` |  |
| `test_deactivate_key` | `` |  |
| `test_activate_key` | `` |  |
| `test_filter_by_provider` | `` |  |
| `test_dashboard` | `` |  |
| `test_delete_key` | `` |  |
| `test_delete_nonexistent` | `` |  |

---

## `projects/big-project/backend/database/db.py`

Database configuration.

*17 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_db` | `` |  |

---

## `projects/big-project/backend/database/models.py`

Database models.

*12 lines*

### class `Example`(Base)

---

## `projects/big-project/backend/main.py`

big-project API
FastAPI application entry point.

*36 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `async root` | `` |  |
| `async health` | `` |  |

---

## `projects/blog-platform/backend/database/db.py`

Database configuration.

*17 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_db` | `` |  |

---

## `projects/blog-platform/backend/database/models.py`

Database models.

*12 lines*

### class `Example`(Base)

---

## `projects/blog-platform/backend/main.py`

blog-platform API
FastAPI application entry point.

*36 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `async root` | `` |  |
| `async health` | `` |  |

---

## `setup.py`

MyWork-AI Framework Setup
=========================
Installation script for MyWork-AI framework tools.

*97 lines*

---

## `tests/__init__.py`

MyWork-AI Framework Tests
=========================
Test suite for the MyWork-AI framework tools.

*5 lines*

---

## `tests/conftest.py`

Pytest Configuration and Fixtures
==================================
Shared fixtures and configuration for all tests.

*145 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `temp_mywork_root` | `tmp_path` | Create a temporary MyWork root directory for testing. |
| `temp_project` | `temp_mywork_root` | Create a temporary project for testing. |
| `sample_brain_data` | `temp_mywork_root` | Create sample brain data for testing. |
| `sample_module_registry` | `temp_mywork_root` | Create sample module registry for testing. |

---

## `tests/test_analytics.py`

Tests for analytics engine.

*70 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `test_get_project_root` | `` |  |
| `test_analyze_languages` | `` |  |
| `test_analyze_complexity` | `` |  |
| `test_analyze_security` | `` |  |
| `test_analyze_deps` | `` |  |
| `test_analyze_git_trends` | `` |  |
| `test_complexity_avg_lines` | `` |  |
| `test_security_env_example_exists` | `` |  |

---

## `tests/test_autoforge.py`

Tests for AutoForge integration modules.

*180 lines*

### class `TestAutoForgeAPI`

Test AutoForge API integration.

| Method | Args | Description |
|--------|------|-------------|
| `test_module_imports_successfully` | `` | Test that autoforge_api module can be imported without errors. |
| `test_autoforge_branding_in_docstring` | `` | Test that module docstring references AutoForge, not Autocoder. |
| `test_server_status_check` | `mock_get` | Test server status checking functionality. |
| `test_config_constants` | `` | Test that configuration constants are properly set. |

### class `TestAutoForgeService`

Test AutoForge Service management.

| Method | Args | Description |
|--------|------|-------------|
| `test_service_module_imports_successfully` | `` | Test that autoforge_service module can be imported. |
| `test_service_branding_in_docstring` | `` | Test that service module docstring references AutoForge. |
| `test_service_has_expected_structure` | `` | Test that service module has expected imports and structure. |

### class `TestBackwardsCompatibility`

Test that backwards compatibility aliases work correctly.

| Method | Args | Description |
|--------|------|-------------|
| `test_autocoder_api_alias_exists` | `` | Test that autocoder_api.py still exists as alias/symlink. |
| `test_autocoder_service_alias_exists` | `` | Test that autocoder_service.py still exists as alias/symlink. |
| `test_autocoder_aliases_point_to_autoforge` | `` | Test that old autocoder files are symlinks to new autoforge files. |

### class `TestCLIIntegration`

Test CLI integration with AutoForge commands.

| Method | Args | Description |
|--------|------|-------------|
| `test_autoforge_commands_available` | `` | Test that AutoForge commands are available in CLI. |
| `test_legacy_command_mapping` | `` | Test that legacy 'ac' commands still work. |
| `test_af_command_calls_autoforge_function` | `mock_cmd` | Test that 'mw af' calls the correct function. |
| `test_ac_legacy_command_calls_autoforge_function` | `mock_cmd` | Test that 'mw ac' (legacy) still calls AutoForge function. |

### class `TestDocumentationConsistency`

Test that documentation and help text is consistent with AutoForge branding.

| Method | Args | Description |
|--------|------|-------------|
| `test_help_text_mentions_autoforge` | `` | Test that help documentation mentions AutoForge, not Autocoder. |
| `test_autoforge_api_help_consistent` | `` | Test that AutoForge API help text is consistent. |
| `test_no_old_autocoder_references_in_help` | `` | Test that help text doesn't contain old Autocoder references. |

---

## `tests/test_brain.py`

Tests for brain.py
==================
Tests for the Brain/Knowledge Vault functionality.

*326 lines*

### class `TestBrainManager`

Tests for BrainManager class.

| Method | Args | Description |
|--------|------|-------------|
| `test_load_empty_brain` | `temp_mywork_root` | Should handle empty/missing brain file gracefully. |
| `test_load_existing_brain` | `temp_mywork_root, sample_brain_data` | Should load existing brain data correctly. |
| `test_add_entry` | `temp_mywork_root` | Should add new entries correctly. |
| `test_search_entries` | `temp_mywork_root, sample_brain_data` | Should search entries by query. |
| `test_search_no_results` | `temp_mywork_root, sample_brain_data` | Should return empty list when no matches. |
| `test_get_by_type` | `temp_mywork_root, sample_brain_data` | Should filter entries by type. |
| `test_update_entry` | `temp_mywork_root, sample_brain_data` | Should update existing entries. |
| `test_get_stats` | `temp_mywork_root, sample_brain_data` | Should return correct statistics. |

### class `TestBrainDeprecateAndCleanup`

Tests for deprecate, delete, and cleanup operations.

| Method | Args | Description |
|--------|------|-------------|
| `test_deprecate_entry` | `temp_mywork_root, sample_brain_data` | Should mark an entry as deprecated. |
| `test_deprecate_nonexistent` | `temp_mywork_root` | Should return None for nonexistent entry. |
| `test_delete_entry` | `temp_mywork_root, sample_brain_data` | Should permanently delete an entry. |
| `test_delete_nonexistent` | `temp_mywork_root` | Should return False for nonexistent entry. |
| `test_cleanup_removes_deprecated` | `temp_mywork_root, sample_brain_data` | Should remove all deprecated entries. |
| `test_cleanup_nothing_to_remove` | `temp_mywork_root, sample_brain_data` | Should return 0 when no deprecated entries. |
| `test_get_deprecated` | `temp_mywork_root, sample_brain_data` | Should return only deprecated entries. |
| `test_get_experimental` | `temp_mywork_root` | Should return only experimental entries. |
| `test_add_invalid_type` | `temp_mywork_root` | Should raise ValueError for invalid entry type. |

### class `TestBrainEntry`

Tests for BrainEntry dataclass.

| Method | Args | Description |
|--------|------|-------------|
| `test_create_entry` | `` | Should create entry with all fields. |
| `test_to_dict` | `` | Should convert to dictionary correctly. |

---

## `tests/test_brain_quality.py`

Tests for Brain Quality Scoring & Deduplication Engine (Phase 9).

*227 lines*

### class `FakeEntry`

Minimal brain entry for testing.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `id, content, context, tags, status` |  |

### class `FakeBrain`

Minimal brain manager for testing.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `entries` |  |
| `save` | `` |  |

### class `TestQualityScorer`

| Method | Args | Description |
|--------|------|-------------|
| `test_score_high_quality_entry` | `` |  |
| `test_score_low_quality_entry` | `` |  |
| `test_score_all_returns_sorted` | `` |  |
| `test_grade_boundaries` | `` |  |
| `test_recency_scoring` | `` |  |
| `test_empty_brain` | `` |  |

### class `TestDuplicateDetector`

| Method | Args | Description |
|--------|------|-------------|
| `test_exact_duplicates` | `` |  |
| `test_fuzzy_duplicates` | `` |  |
| `test_no_duplicates` | `` |  |
| `test_dedupe_dry_run` | `` |  |
| `test_dedupe_apply` | `` |  |

### class `TestProvenanceTracker`

| Method | Args | Description |
|--------|------|-------------|
| `test_record_and_get` | `tmp_path` |  |
| `test_report_empty` | `tmp_path` |  |
| `test_multiple_accesses` | `tmp_path` |  |

### class `TestQualityReport`

| Method | Args | Description |
|--------|------|-------------|
| `test_report_with_entries` | `` |  |
| `test_report_empty` | `` |  |

---

## `tests/test_brain_search.py`

Tests for brain search functionality.

Tests TF-IDF search, ranking, and edge cases in the brain knowledge base.

*322 lines*

### class `TestBrainTFIDFSearch`

Test TF-IDF search functionality in brain.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test brain with sample data. |
| `test_basic_search_finds_relevant_entries` | `` | Test basic search functionality. |
| `test_search_ranking_order` | `` | Test that search results are ranked by relevance. |
| `test_search_empty_query` | `` | Test search with empty query. |
| `test_search_no_results` | `` | Test search that should return no results. |
| `test_search_case_insensitive` | `` | Test that search is case insensitive. |
| `test_search_by_tags` | `` | Test searching entries by tags. |
| `test_search_by_content` | `` | Test searching entries by content. |
| `test_search_by_context` | `` | Test searching entries by context field. |
| `test_multi_word_search` | `` | Test search with multiple words. |
| `test_search_filters_by_type` | `` | Test that search can work across different entry types. |
| `test_search_with_special_characters` | `` | Test search handles special characters gracefully. |

### class `TestBrainSearchEdgeCases`

Test edge cases and error conditions.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up minimal test brain. |
| `test_search_empty_brain` | `` | Test search on empty brain. |
| `test_search_single_entry_brain` | `` | Test search with only one entry. |
| `test_search_very_long_query` | `` | Test search with very long query string. |
| `test_search_unicode_content` | `` | Test search with unicode content. |

### class `TestBrainSearchPerformance`

Test search performance characteristics.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up brain with many entries. |
| `test_search_performance_many_entries` | `` | Test search performance with many entries. |
| `test_multiple_searches_consistent` | `` | Test that multiple searches return consistent results. |

---

## `tests/test_config.py`

Tests for config.py
====================
Tests for the shared configuration module.

*150 lines*

### class `TestGetMyworkRoot`

Tests for get_mywork_root function.

| Method | Args | Description |
|--------|------|-------------|
| `test_uses_environment_variable` | `temp_mywork_root` | Should use MYWORK_ROOT environment variable when set. |
| `test_detects_from_script_location` | `tmp_path` | Should detect root from script location when env not set. |

### class `TestPathConstants`

Tests for path constant definitions.

| Method | Args | Description |
|--------|------|-------------|
| `test_tools_dir_exists` | `temp_mywork_root` | TOOLS_DIR should be a valid path. |
| `test_projects_dir_constant` | `temp_mywork_root` | PROJECTS_DIR should be correct. |
| `test_planning_dir_constant` | `temp_mywork_root` | PLANNING_DIR should be correct. |

### class `TestEnsureDirectories`

Tests for ensure_directories function.

| Method | Args | Description |
|--------|------|-------------|
| `test_creates_required_directories` | `temp_mywork_root` | Should create all required directories. |

### class `TestHelperFunctions`

Tests for helper functions.

| Method | Args | Description |
|--------|------|-------------|
| `test_get_project_path` | `temp_mywork_root` | Should return correct project path. |
| `test_list_projects_empty` | `temp_mywork_root` | Should return empty list when no projects exist. |
| `test_list_projects_with_projects` | `temp_mywork_root, temp_project` | Should return list of project paths. |
| `test_list_projects_excludes_hidden` | `temp_mywork_root` | Should exclude hidden and template directories. |

---

## `tests/test_health_check.py`

Tests for health_check.py
=========================
Tests for the Health Check functionality including utility functions,
HealthCheckLock, Status enum, and HealthChecker methods.

*136 lines*

### class `TestStatus`

Tests for the Status enum.

| Method | Args | Description |
|--------|------|-------------|
| `test_status_values` | `temp_mywork_root` |  |

### class `TestCheckFilePermissions`

Tests for the check_file_permissions utility.

| Method | Args | Description |
|--------|------|-------------|
| `test_readable_file` | `temp_mywork_root` |  |
| `test_nonexistent_file_with_existing_parent` | `temp_mywork_root` |  |
| `test_writable_directory` | `temp_mywork_root` |  |

### class `TestSafeSocketConnect`

Tests for safe_socket_connect.

| Method | Args | Description |
|--------|------|-------------|
| `test_connection_to_closed_port` | `temp_mywork_root` |  |
| `test_connection_to_invalid_host` | `temp_mywork_root` |  |

### class `TestHealthCheckLock`

Tests for the HealthCheckLock context manager.

| Method | Args | Description |
|--------|------|-------------|
| `test_lock_acquire_and_release` | `temp_mywork_root` |  |
| `test_lock_creates_parent_dirs` | `temp_mywork_root` |  |

### class `TestHealthChecker`

Tests for HealthChecker instantiation and basic methods.

| Method | Args | Description |
|--------|------|-------------|
| `test_instantiation` | `temp_mywork_root` |  |
| `test_has_run_methods` | `temp_mywork_root` |  |
| `test_quick_check_returns_results` | `temp_mywork_root` |  |

---

## `tests/test_integration.py`

Integration tests for MyWork CLI commands.

Tests end-to-end functionality of the mw command line interface
to ensure all components work together correctly.

*187 lines*

### class `TestMWIntegration`

Integration tests for mw commands.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment before each test. |
| `run_mw_command` | `args, capture_output` | Helper to run mw commands with proper environment. |
| `test_mw_status_command` | `` | Test 'mw status' end-to-end. |
| `test_mw_status_help` | `` | Test 'mw status --help' displays help. |
| `test_mw_brain_stats_command` | `` | Test 'mw brain stats' end-to-end. |
| `test_mw_projects_command` | `` | Test 'mw projects' end-to-end. |
| `test_mw_new_project_basic` | `` | Test 'mw new test-proj basic' creates files. |
| `test_mw_help_command` | `` | Test 'mw --help' shows usage information. |
| `test_mw_invalid_command` | `` | Test mw handles invalid commands gracefully. |

### class `TestMWCommandChaining`

Test command interactions and data persistence.

| Method | Args | Description |
|--------|------|-------------|
| `test_status_after_scan` | `` | Test that status reflects changes after scan. |

---

## `tests/test_module_registry.py`

Tests for module_registry.py
============================
Tests for the Module Registry functionality.

*221 lines*

### class `TestModuleRegistry`

Tests for ModuleRegistry class.

| Method | Args | Description |
|--------|------|-------------|
| `test_load_empty_registry` | `temp_mywork_root` | Should handle empty/missing registry file gracefully. |
| `test_load_existing_registry` | `temp_mywork_root, sample_module_registry` | Should load existing registry data correctly. |
| `test_search_modules` | `temp_mywork_root, sample_module_registry` | Should search modules by query. |
| `test_search_by_type_filter` | `temp_mywork_root, sample_module_registry` | Should filter search by type. |
| `test_get_by_type` | `temp_mywork_root, sample_module_registry` | Should get modules by type. |
| `test_get_by_project` | `temp_mywork_root, sample_module_registry` | Should get modules by project. |
| `test_get_stats` | `temp_mywork_root, sample_module_registry` | Should return correct statistics. |

### class `TestModule`

Tests for Module dataclass.

| Method | Args | Description |
|--------|------|-------------|
| `test_create_module` | `` | Should create module with all fields. |
| `test_to_dict` | `` | Should convert to dictionary correctly. |

### class `TestProjectScanner`

Tests for ProjectScanner class.

| Method | Args | Description |
|--------|------|-------------|
| `test_scan_empty_projects_dir` | `temp_mywork_root` | Should handle empty projects directory. |
| `test_scan_project_with_files` | `temp_mywork_root, temp_project` | Should scan project and find modules. |

---

## `tests/test_mw_cli.py`

Tests for the mw CLI (tools/mw.py).

*132 lines*

### class `TestColors`

Test the Colors helper class.

| Method | Args | Description |
|--------|------|-------------|
| `test_color_codes_are_strings` | `` |  |
| `test_color_function_wraps_text` | `` |  |

### class `TestCommandRouting`

Test that main() routes to the right commands.

| Method | Args | Description |
|--------|------|-------------|
| `test_help_flag` | `` |  |
| `test_help_command` | `` |  |
| `test_no_args_shows_help` | `` |  |
| `test_unknown_command_exits_1` | `` |  |
| `test_dashboard_command_routing` | `` | Test that 'mw dashboard' routes to cmd_dashboard function. |
| `test_autoforge_command_routing` | `` | Test that 'mw af' routes to cmd_autoforge function. |
| `test_autoforge_legacy_alias` | `` | Test that 'mw ac' still routes to cmd_autoforge for backwards compatibility. |

### class `TestDashboard`

Test the dashboard command functionality.

| Method | Args | Description |
|--------|------|-------------|
| `test_dashboard_runs_without_error` | `` | Test that dashboard command executes without crashing. |
| `test_dashboard_handles_git_errors_gracefully` | `` | Test dashboard gracefully handles git command failures. |
| `test_dashboard_shows_project_count` | `` | Test that dashboard correctly counts projects. |
| `test_command_case_insensitive` | `` | Commands should be lowercased before routing. |

### class `TestRunTool`

Test the run_tool helper.

| Method | Args | Description |
|--------|------|-------------|
| `test_run_tool_missing_script` | `` | Running a non-existent tool should return non-zero. |

### class `TestSearchRequiresArgs`

Test that search without query prints usage.

| Method | Args | Description |
|--------|------|-------------|
| `test_search_no_args` | `capsys` |  |

### class `TestPrintHelp`

Test help output.

| Method | Args | Description |
|--------|------|-------------|
| `test_print_help_runs` | `capsys` |  |

---

## `tests/test_performance.py`

Performance benchmarks for MyWork CLI.

Tests that core operations complete within acceptable time limits
to ensure good user experience.

*346 lines*

### class `TestCLIPerformance`

Test CLI startup and command performance.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment. |
| `run_mw_command_timed` | `args` | Run mw command and measure execution time. |
| `test_cli_startup_time_under_2_seconds` | `` | Test that CLI startup time is under 2 seconds. |
| `test_status_command_performance` | `` | Test that status command completes quickly. |
| `test_projects_command_performance` | `` | Test that projects listing is fast. |
| `test_help_commands_are_instant` | `` | Test that help commands are nearly instant. |

### class `TestBrainPerformance`

Test brain search performance.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment. |
| `run_brain_command_timed` | `args` | Run brain command and measure execution time. |
| `test_brain_search_under_1_second` | `` | Test that brain search completes under 1 second. |
| `test_brain_stats_performance` | `` | Test that brain stats is fast. |

### class `TestScaffoldPerformance`

Test scaffold/project creation performance.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment. |
| `run_scaffold_command_timed` | `args` | Run scaffold command and measure execution time. |
| `test_basic_scaffold_under_3_seconds` | `` | Test that basic project creation is under 3 seconds. |
| `test_fastapi_scaffold_reasonable_time` | `` | Test that FastAPI project creation is reasonably fast. |
| `test_template_listing_fast` | `` | Test that template listing is very fast. |

### class `TestOverallPerformance`

Test overall system performance characteristics.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment. |
| `test_multiple_commands_no_slowdown` | `` | Test that running multiple commands doesn't cause slowdown. |
| `test_concurrent_command_handling` | `` | Test that system can handle concurrent commands reasonably. |

---

## `tests/test_scaffold.py`

Tests for the scaffold.py project creation tool.

Tests template generation, project validation, and file structure creation.

*343 lines*

### class `TestScaffoldTemplates`

Test scaffold template generation.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment. |
| `teardown_method` | `` | Clean up test environment. |
| `test_basic_template_generates_correct_files` | `` | Test basic template creates the expected file structure. |
| `test_fastapi_template_generates_correct_files` | `` | Test FastAPI template creates backend structure. |
| `test_nextjs_template_generates_correct_files` | `` | Test Next.js template creates frontend structure. |
| `test_fullstack_template_generates_both_stacks` | `` | Test fullstack template creates both backend and frontend. |
| `test_cli_template_generates_cli_structure` | `` | Test CLI template creates Python CLI structure. |
| `test_invalid_template_name_raises_error` | `` | Test that invalid template names are handled properly. |

### class `TestProjectNameValidation`

Test project name validation rules.

| Method | Args | Description |
|--------|------|-------------|
| `setup_method` | `` | Set up test environment. |
| `teardown_method` | `` | Clean up test environment. |
| `test_valid_project_names` | `` | Test that valid project names are accepted. |
| `test_invalid_project_names` | `` | Test that invalid project names are rejected. |
| `test_existing_project_name_rejected` | `` | Test that existing project names are rejected. |

### class `TestCreateStructureFunction`

Test the create_structure helper function.

| Method | Args | Description |
|--------|------|-------------|
| `test_creates_nested_directories` | `` | Test creating nested directory structures. |
| `test_template_substitution` | `` | Test template variable substitution. |
| `test_handles_literal_braces` | `` | Test that literal braces in templates are preserved. |

### class `TestListTemplates`

Test template listing functionality.

| Method | Args | Description |
|--------|------|-------------|
| `test_list_templates_shows_all_templates` | `capsys` | Test that list_templates shows all available templates. |

---

## `tools/_template.py`

Tool: [Name]
Purpose: [What this tool does]

Usage:
    python tools/_template.py --input "value"

Environment Variables Required:
    - API_KEY: Description

*42 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `input_value` | Main function that performs the tool's task. |

---

## `tools/ai_docs.py`

AI Documentation Generator
==========================
Scans a project directory and uses AI to generate comprehensive documentation.

Usage:
    python ai_docs.py <project_path>        # Generate docs for project
    python ai_docs.py --current             # Generate docs for current directory
    mw docs generate <project>              # Via CLI

*613 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `call_openrouter_api` | `prompt` | Call OpenRouter API with the given prompt. |
| `scan_project` | `project_path` | Scan project directory and collect information. |
| `analyze_file` | `file_path, rel_path` | Analyze a single file. |
| `detect_language` | `file_path` | Detect programming language from file extension. |
| `extract_functions` | `content, language` | Extract function names from code (basic regex-based). |
| `extract_classes` | `content, language` | Extract class names from code. |
| `extract_imports` | `content, language` | Extract import statements from code. |
| `extract_dependencies` | `file_path, filename` | Extract dependencies from config files. |
| `detect_frameworks` | `project_info` | Detect frameworks based on dependencies and file structure. |
| `find_entry_points` | `project_info` | Find entry points of the application. |
| `generate_readme` | `project_info` | Generate README.md using AI. |
| `generate_api_docs` | `project_info` | Generate API documentation if backend detected. |
| `generate_setup_guide` | `project_info` | Generate detailed setup guide. |
| `format_file_structure` | `files` | Format file structure for display. |
| `format_backend_files` | `files` | Format backend-related files. |
| `save_documentation` | `project_path, docs` | Save generated documentation to files. |
| `main` | `` | Main function to handle command line arguments. |

---

## `tools/ai_review.py`

AI Code Review Tool
==================
Uses OpenRouter API to review code quality and provide suggestions.

Usage:
    python ai_review.py <file>              # Review specific file
    python ai_review.py --diff              # Review git diff
    python ai_review.py --staged            # Review staged changes
    mw review <file>                        # Via CLI
    mw review --diff                        # Via CLI

*247 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `call_openrouter_api` | `prompt` | Call OpenRouter API with the given prompt. |
| `get_git_diff` | `staged` | Get git diff output. |
| `detect_language` | `file_path` | Detect programming language from file extension. |
| `create_review_prompt` | `code, language, context` | Create the prompt for code review. |
| `review_file` | `file_path` | Review a specific file. |
| `review_diff` | `staged` | Review git diff. |
| `format_output` | `result` | Format the review output for display. |
| `main` | `` | Main function to handle command line arguments. |

---

## `tools/analytics.py`

MyWork Analytics Engine
=======================
Project analytics, code insights, and health trends.

Commands:
    mw analytics              Full project analytics report
    mw analytics summary      Quick summary
    mw analytics deps         Dependency health check
    mw analytics complexity   Code complexity analysis
    mw analytics trends       Git activity trends
    mw analytics security     Security posture overview

*443 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `color` | `text, code` |  |
| `green` | `t` |  |
| `red` | `t` |  |
| `yellow` | `t` |  |
| `blue` | `t` |  |
| `cyan` | `t` |  |
| `bold` | `t` |  |
| `dim` | `t` |  |
| `run_cmd` | `cmd, cwd` | Run shell command and return output. |
| `get_project_root` | `` | Find project root (has .git or pyproject.toml or package.json). |
| `analyze_languages` | `root` | Count lines by language. |
| `analyze_git_trends` | `root` | Analyze git commit patterns. |
| `analyze_deps` | `root` | Check dependency health. |
| `analyze_complexity` | `root` | Simple code complexity analysis. |
| `analyze_security` | `root` | Basic security posture check. |
| `print_bar` | `label, value, max_val, width` | Print a horizontal bar. |
| `print_section` | `title` |  |
| `cmd_analytics` | `args` | Run project analytics. |

---

## `tools/auto_lint_fixer.py`

Automatic Markdownlint Fixer
Fixes common markdownlint violations across the MyWork repository.

Handles:
- MD022: Headings without surrounding blank lines
- MD032: Lists without surrounding blank lines
- MD031: Fenced code blocks without blank lines
- MD047: Missing trailing newline
- MD058: Tables without blank lines
- MD024: Duplicate headings (warns only)
- MD036: Emphasis used as heading (warns only)

*891 lines*

### class `AutoLintFixer`

Simple wrapper class for integration with auto_linting_agent.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `root_dir` |  |
| `fix_file` | `filepath` | Fix a single markdown file and return number of issues fixed. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `run_markdownlint` | `directory` | Run markdownlint and capture violations. |
| `fix_md022_headings` | `content` | Fix MD022: Add blank lines around headings. |
| `fix_md032_lists` | `content` | Fix MD032: Add blank lines around lists. |
| `fix_md031_fences` | `content` | Fix MD031: Add blank lines around fenced code blocks. |
| `fix_md047_trailing_newline` | `content` | Fix MD047: Ensure file ends with single newline. |
| `fix_md058_tables` | `content` | Fix MD058: Add blank lines around tables. |
| `fix_md040_code_language` | `content` | Fix MD040: Add language specification to fenced code blocks. |
| `detect_code_language` | `content_lines` | Detect the programming language from code content. |
| `fix_md013_line_length` | `content, max_length` | Fix MD013: Wrap long lines intelligently. |
| `wrap_table_line` | `line, max_length` | Intelligently wrap table lines by shortening cell content. |
| `wrap_list_item` | `line, max_length` | Wrap long list items. |
| `wrap_regular_text` | `line, max_length` | Wrap regular text lines. |
| `fix_md034_bare_urls` | `content` | Fix MD034: Wrap bare URLs in angle brackets. |
| `fix_md046_code_block_style` | `content` | Fix MD046: Convert indented code blocks to fenced style. |
| `fix_md051_link_fragments` | `content` | Fix MD051: Fix invalid link fragments. |
| `fix_md031_fences_enhanced` | `content` | Enhanced MD031: Better fenced code block spacing. |
| `fix_md060_table_style` | `content` | Fix MD060: Table column style (add spaces around pipes). |
| `fix_file` | `filepath` | Fix markdownlint violations in a single file. |
| `find_markdown_files` | `directory` | Find all markdown files, excluding node_modules. |
| `main` | `` | Main execution function. |

---

## `tools/auto_lint_scheduler.py`

Automated Markdownlint Scheduler
Runs markdownlint fixes on a scheduled interval (default: every 4 hours).

Usage:
    python3 tools/auto_lint_scheduler.py          # Run once
    python3 tools/auto_lint_scheduler.py --daemon # Run continuously every 4 hours

*207 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `run_command` | `command, cwd` | Run a command and return success status and output. |
| `check_git_status` | `` | Check git status and count markdown changes. |
| `run_lint_fixer` | `` | Run the auto lint fixer and return results. |
| `commit_changes` | `results, interval_seconds` | Commit the linting fixes to git. |
| `run_single_cycle` | `interval_seconds, force` | Run a single lint-fix-commit cycle. |
| `main` | `` | Main execution function. |

---

## `tools/auto_linting_agent.py`

Auto-Linting Agent - Continuously monitors and fixes linting issues
Part of the MyWork Framework

Features:
- Watches files for changes
- Runs appropriate linters
- Auto-fixes common issues
- Supports multiple linting tools
- Integrates with Git workflows

*568 lines*

### class `LintResult`

Result of a linting operation

### class `LintConfig`

Configuration for linting tools

### class `AutoLintingAgent`

Main auto-linting agent class

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `root_dir, config` |  |
| `should_ignore_file` | `file_path` | Check if file should be ignored based on patterns |
| `get_linting_tools_for_file` | `file_path` | Determine which linting tools to use for a file |
| `run_markdownlint` | `file_path` | Run markdownlint and fix issues |
| `run_black` | `file_path` | Run Black Python formatter |
| `run_prettier` | `file_path` | Run Prettier formatter |
| `run_eslint` | `file_path` | Run ESLint with auto-fix |
| `run_flake8` | `file_path` | Run Flake8 (checking only, no auto-fix) |
| `lint_file` | `file_path` | Lint a single file with appropriate tools |
| `lint_directory` | `directory` | Lint all files in a directory |
| `save_results` | `results` | Save linting results to JSON file |
| `print_summary` | `results` | Print summary of linting results |

### class `LintingEventHandler`(FileSystemEventHandler)

File system event handler for watching file changes

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `agent` |  |
| `on_modified` | `event` |  |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main CLI entry point |

---

## `tools/auto_update.py`

Auto-Update System for MyWork Framework
========================================
Safely updates GSD, Autocoder, n8n-skills, and n8n-mcp without breaking the system.

Usage:
    python auto_update.py check          # Check for available updates
    python auto_update.py update [component]  # Update specific or all components
    python auto_update.py status         # Show current versions
    python auto_update.py rollback [component]  # Rollback to previous version

Components: gsd, autocoder, n8n-skills, n8n-mcp, all

*544 lines*

### class `Logger`

Simple logger for update operations.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `log_file` |  |
| `log` | `message, level` |  |
| `info` | `message` |  |
| `error` | `message` |  |
| `success` | `message` |  |
| `warning` | `message` |  |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `run_command` | `cmd, cwd, capture` | Run a shell command and return success status and output. |
| `get_git_info` | `path` | Get current git information for a repository. |
| `get_npx_info` | `package` | Get npm package version info. |
| `check_autocoder_running` | `` | Check if Autocoder server is running before update. |
| `rebuild_autocoder_ui` | `` | Rebuild Autocoder UI after update. |
| `backup_component` | `component` | Create a backup of a component before updating. |
| `update_git_component` | `component, dry_run` | Update a git-based component. |
| `update_npx_component` | `component, dry_run` | Update an npx-based component (clears cache to get latest). |
| `get_status` | `` | Get status of all components. |
| `check_updates` | `` | Check which components have updates available. |
| `rollback_component` | `component` | Rollback a component to the previous version. |
| `print_status` | `` | Print formatted status of all components. |
| `update_component` | `component, dry_run` | Update a single component. |
| `update_all` | `dry_run` | Update all components. |
| `main` | `` | Main entry point. |

---

## `tools/autocoder_api.py`

AutoForge API Integration Tool
==============================
Provides programmatic control over AutoForge with both automatic and manual modes.

AutoForge Server: http://127.0.0.1:8888
WebSocket: ws://127.0.0.1:8888/ws/projects/{project_name}

Reference: https://github.com/AutoForgeAI/autoforge

Usage:
    # Check if AutoForge server is running
    python tools/autoforge_api.py status

    # Start a project (automatic mode)
    python tools/autoforge_api.py start my-project --concurrency 3

    # Stop a running project
    python tools/autoforge_api.py stop my-project

    # Get project progress
    python tools/autoforge_api.py progress my-project

    # Open AutoForge UI (manual mode)
    python tools/autoforge_api.py ui

    # Start server if not running
    python tools/autoforge_api.py server

*440 lines*

### class `AutoForgeAPI`

Client for AutoForge REST API.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `base_url` |  |
| `is_server_running` | `` | Check if AutoForge server is running. |
| `get_agent_status` | `project_name` | Get current agent status for a project. |
| `start_agent` | `project_name, model, concurrency, yolo_mode, testing_ratio` | Start the AutoForge agent for a project. |
| `stop_agent` | `project_name` | Stop the running agent. |
| `pause_agent` | `project_name` | Pause the running agent. |
| `resume_agent` | `project_name` | Resume a paused agent. |
| `get_features` | `project_name` | Get feature progress for a project. |
| `list_projects` | `` | List all registered projects. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_autoforge_python` | `` | Prefer AutoForge venv python when available. |
| `start_server` | `` | Start the AutoForge server. |
| `open_ui` | `` | Open the AutoForge UI in browser. |
| `get_progress` | `project_name` | Get detailed progress for a project. |
| `notify_webhook` | `event, data` | Send notification to n8n webhook if configured. |
| `main` | `` |  |

---

## `tools/autocoder_service.py`

AutoForge Service Manager
=========================
Manages the AutoForge server as a macOS LaunchAgent service.

The service runs automatically on login and restarts if it crashes.

Usage:
    python tools/autoforge_service.py install   # Install and start service
    python tools/autoforge_service.py start     # Start service
    python tools/autoforge_service.py stop      # Stop service
    python tools/autoforge_service.py restart   # Restart service
    python tools/autoforge_service.py status    # Check service status
    python tools/autoforge_service.py logs      # View logs
    python tools/autoforge_service.py uninstall # Remove service

*346 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_autoforge_python` | `` | Prefer AutoForge venv python when available. |
| `generate_plist` | `` | Generate LaunchAgent plist content. |
| `setup` | `` | Create or update the LaunchAgent plist. |
| `run_cmd` | `cmd, check` | Run a command and return the result. |
| `is_loaded` | `` | Check if the service is loaded. |
| `is_running` | `` | Check if the server is actually responding. |
| `get_pid` | `` | Get the PID of the running service. |
| `install` | `` | Install and load the service. |
| `start` | `` | Start the service. |
| `stop` | `` | Stop the service. |
| `restart` | `` | Restart the service. |
| `status` | `` | Show service status. |
| `logs` | `follow, lines` | View service logs. |
| `uninstall` | `` | Uninstall the service. |
| `main` | `` |  |

---

## `tools/autoforge_api.py`

AutoForge API Integration Tool
==============================
Provides programmatic control over AutoForge with both automatic and manual modes.

AutoForge Server: http://127.0.0.1:8888
WebSocket: ws://127.0.0.1:8888/ws/projects/{project_name}

Reference: https://github.com/AutoForgeAI/autoforge

Usage:
    # Check if AutoForge server is running
    python tools/autoforge_api.py status

    # Start a project (automatic mode)
    python tools/autoforge_api.py start my-project --concurrency 3

    # Stop a running project
    python tools/autoforge_api.py stop my-project

    # Get project progress
    python tools/autoforge_api.py progress my-project

    # Open AutoForge UI (manual mode)
    python tools/autoforge_api.py ui

    # Start server if not running
    python tools/autoforge_api.py server

*440 lines*

### class `AutoForgeAPI`

Client for AutoForge REST API.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `base_url` |  |
| `is_server_running` | `` | Check if AutoForge server is running. |
| `get_agent_status` | `project_name` | Get current agent status for a project. |
| `start_agent` | `project_name, model, concurrency, yolo_mode, testing_ratio` | Start the AutoForge agent for a project. |
| `stop_agent` | `project_name` | Stop the running agent. |
| `pause_agent` | `project_name` | Pause the running agent. |
| `resume_agent` | `project_name` | Resume a paused agent. |
| `get_features` | `project_name` | Get feature progress for a project. |
| `list_projects` | `` | List all registered projects. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_autoforge_python` | `` | Prefer AutoForge venv python when available. |
| `start_server` | `` | Start the AutoForge server. |
| `open_ui` | `` | Open the AutoForge UI in browser. |
| `get_progress` | `project_name` | Get detailed progress for a project. |
| `notify_webhook` | `event, data` | Send notification to n8n webhook if configured. |
| `main` | `` |  |

---

## `tools/autoforge_service.py`

AutoForge Service Manager
=========================
Manages the AutoForge server as a macOS LaunchAgent service.

The service runs automatically on login and restarts if it crashes.

Usage:
    python tools/autoforge_service.py install   # Install and start service
    python tools/autoforge_service.py start     # Start service
    python tools/autoforge_service.py stop      # Stop service
    python tools/autoforge_service.py restart   # Restart service
    python tools/autoforge_service.py status    # Check service status
    python tools/autoforge_service.py logs      # View logs
    python tools/autoforge_service.py uninstall # Remove service

*346 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_autoforge_python` | `` | Prefer AutoForge venv python when available. |
| `generate_plist` | `` | Generate LaunchAgent plist content. |
| `setup` | `` | Create or update the LaunchAgent plist. |
| `run_cmd` | `cmd, check` | Run a command and return the result. |
| `is_loaded` | `` | Check if the service is loaded. |
| `is_running` | `` | Check if the server is actually responding. |
| `get_pid` | `` | Get the PID of the running service. |
| `install` | `` | Install and load the service. |
| `start` | `` | Start the service. |
| `stop` | `` | Stop the service. |
| `restart` | `` | Restart the service. |
| `status` | `` | Show service status. |
| `logs` | `follow, lines` | View service logs. |
| `uninstall` | `` | Uninstall the service. |
| `main` | `` |  |

---

## `tools/brain.py`

Brain Manager for Master Orchestrator
======================================
Manages the persistent knowledge vault (BRAIN.md).

Usage:
    python brain.py add <type> <content>    # Add new knowledge
    python brain.py update <id> <content>   # Update existing entry
    python brain.py deprecate <id>          # Mark as deprecated
    python brain.py search <query>          # Search the brain
    python brain.py review                  # Show entries needing attention
    python brain.py cleanup                 # Remove deprecated entries
    python brain.py stats                   # Show brain statistics
    python brain.py analytics              # Comprehensive analytics dashboard
    python brain.py export [markdown|json|csv] # Export to markdown, JSON, or CSV
    python brain.py import <file>           # Import from JSON/markdown/CSV
    python brain.py backup                  # Create timestamped backup
    python brain.py restore <backup>        # Restore from backup

Types:
    lesson      - Something learned from experience
    pattern     - A proven approach that works
    antipattern - Something to avoid
    tip         - Quick tool/usage tip
    insight     - Integration or architecture insight
    experiment  - Something to try

Examples:
    python brain.py add lesson "Always validate before deploy" --context "Broke prod once"
    python brain.py add pattern "Error Handling" --steps "1. Log\n2. Notify\n3. Recover"
    python brain.py search "api"
    python brain.py deprecate lesson-003

*1699 lines*

### class `BrainEntry`

Represents a single piece of knowledge.

| Method | Args | Description |
|--------|------|-------------|
| `to_dict` | `` |  |
| `from_dict` | `cls, data` |  |

### class `BrainManager`

Manages the brain knowledge base.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `root` |  |
| `load` | `` | Load entries from JSON backup if exists. |
| `save` | `` | Save entries to JSON backup. |
| `generate_id` | `entry_type` | Generate a unique ID for an entry. |
| `add` | `entry_type, content, context, status, tags` | Add a new entry to the brain. |
| `update` | `entry_id, content, context, status, tags` | Update an existing entry. |
| `deprecate` | `entry_id` | Mark an entry as deprecated. |
| `delete` | `entry_id` | Delete an entry permanently. |
| `search` | `query` | Search entries by content, context, or tags. |
| `get_by_type` | `entry_type` | Get all entries of a specific type. |
| `get_deprecated` | `` | Get all deprecated entries. |
| `get_experimental` | `` | Get all experimental entries. |
| `cleanup` | `` | Remove all deprecated entries. |
| `get_stats` | `` | Get brain statistics. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `print_entry` | `entry, verbose` | Print a formatted entry with improved styling. |
| `cmd_add` | `args` | Add a new entry. |
| `cmd_update` | `args` | Update an existing entry. |
| `cmd_deprecate` | `args` | Mark an entry as deprecated. |
| `cmd_search` | `args` | Search the brain with improved formatting. |
| `cmd_review` | `args` | Show entries needing attention. |
| `cmd_cleanup` | `args` | Remove deprecated entries. |
| `cmd_stats` | `args` | Show brain statistics. |
| `cmd_analytics` | `args` | Show comprehensive brain analytics. |
| `cmd_export` | `args` | Export brain to markdown, JSON, or CSV. |
| `cmd_import` | `args` | Import brain entries from JSON, CSV, or Markdown. |
| `cmd_backup` | `args` | Create a timestamped backup of the brain. |
| `cmd_restore` | `args` | Restore brain from a backup file. |
| `cmd_list` | `args` | List all entries or by type. |
| `cmd_remember` | `args` | Quick add - for use from conversation context. |
| `cmd_learn_git` | `args` | Learn from git commit messages automatically. |
| `extract_learnings_from_commit` | `message, commit_hash, date, author` | Extract potential learnings from a git commit message. |
| `main` | `` | Main entry point. |

---

## `tools/brain_graph.py`

Brain Knowledge Graph and Connection Analysis
============================================
Analyzes and visualizes relationships between brain entries.

Usage:
    python brain_graph.py graph                    # Show ASCII knowledge graph
    python brain_graph.py related <entry_id>       # Find related entries
    python brain_graph.py cluster                  # Group similar knowledge
    python brain_graph.py connections <entry_id>   # Detailed connection analysis
    python brain_graph.py network-stats            # Network statistics
    python brain_graph.py export-graph             # Export graph as JSON

Features:
- Auto-detect relationships via shared tags and content similarity
- ASCII visualization of knowledge connections
- Clustering algorithm to group related knowledge
- Connection strength scoring
- Network analysis metrics

*756 lines*

### class `KnowledgeGraph`

Represents a knowledge graph of brain entries and their connections.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `brain_manager` |  |
| `get_related_entries` | `entry_id, limit` | Get entries related to the given entry, sorted by connection strength. |
| `get_clusters` | `min_cluster_size` | Group related entries into clusters using a simple greedy algorithm. |
| `get_network_stats` | `` | Calculate network statistics. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `print_ascii_graph` | `graph, max_nodes` | Print an ASCII representation of the knowledge graph. |
| `cmd_graph` | `args` | Show ASCII knowledge graph visualization. |
| `cmd_related` | `args` | Find entries related to a specific entry. |
| `cmd_cluster` | `args` | Group similar knowledge into clusters. |
| `cmd_connections` | `args` | Detailed connection analysis for an entry. |
| `cmd_network_stats` | `args` | Show detailed network statistics. |
| `cmd_export_graph` | `args` | Export the knowledge graph as JSON. |
| `main` | `` | Main entry point. |

---

## `tools/brain_learner.py`

Brain Learner - Automatic Knowledge Discovery
==============================================
Discovers learnings from work patterns and automatically updates the brain.

This script should be run:
- After completing GSD phases
- After fixing errors
- During weekly maintenance
- After any significant work session

Usage:
    python brain_learner.py discover           # Discover new learnings from recent work
    python brain_learner.py analyze-errors     # Learn from error patterns
    python brain_learner.py analyze-modules    # Learn from module registry patterns
    python brain_learner.py analyze-tracebacks # Learn from Python tracebacks in logs
    python brain_learner.py analyze-deployments # Learn from successful deployments
    python brain_learner.py analyze-reviews    # Learn from code review patterns
    python brain_learner.py auto-tag           # Auto-tag entries based on content
    python brain_learner.py confidence-score   # Update confidence scores for entries
    python brain_learner.py promote            # Promote validated EXPERIMENTAL entries
    python brain_learner.py cleanup-smart      # Intelligent cleanup based on usage
    python brain_learner.py daily              # Run daily learning routine
    python brain_learner.py weekly             # Run weekly deep analysis

The brain learns from:
- GSD phase completions (SUMMARY.md, VERIFICATION.md)
- Git commit patterns
- Error logs and their resolutions
- Module registry patterns
- Health check history
- Successful workflows

*1023 lines*

### class `LearningEngine`

Discovers and extracts learnings from work patterns.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `load_learning_log` | `` | Load previous learning sessions. |
| `save_learning_log` | `` | Save learning session. |
| `already_learned` | `content` | Check if we already have this learning. |
| `add_discovery` | `entry_type, content, context, confidence, source` | Add a discovery if not already known. |
| `discover_from_gsd_phases` | `` | Discover learnings from completed GSD phases. |
| `discover_from_git_commits` | `days` | Discover patterns from recent git commits. |
| `discover_from_module_patterns` | `` | Discover patterns from module registry. |
| `discover_from_error_patterns` | `` | Discover patterns from error logs. |
| `promote_validated_entries` | `` | Promote EXPERIMENTAL entries that have been validated. |
| `smart_cleanup` | `` | Intelligent cleanup based on relevance. |
| `discover_from_python_tracebacks` | `` | Learn from Python tracebacks in recent logs. |
| `discover_from_deployments` | `` | Learn from successful deployment patterns. |
| `discover_from_code_reviews` | `` | Learn from code review patterns in git history. |
| `auto_tag_entries` | `` | Automatically tag entries based on content analysis. |
| `calculate_confidence_scores` | `` | Calculate and update confidence scores for auto-learned entries. |
| `commit_discoveries` | `` | Commit all discoveries to the brain. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `run_daily_learning` | `` | Daily learning routine. |
| `run_weekly_learning` | `` | Weekly deep analysis. |
| `run_discover` | `` | Quick discovery run. |
| `main` | `` | Main entry point. |

---

## `tools/brain_quality.py`

Brain Quality Scoring & Deduplication Engine
=============================================
Phase 9 ‚Äî Brain Intelligence

Scores brain entries by quality and detects/removes duplicates.

Features:
- Quality scoring (0-100) based on content richness, metadata, recency
- Duplicate detection via content similarity (fuzzy + exact)
- Batch dedupe with merge support
- Provenance tracking (who added, when, usage count)
- CLI interface for quality reports

Usage:
    python brain_quality.py score              # Score all entries
    python brain_quality.py dedupe             # Find & remove duplicates
    python brain_quality.py report             # Full quality report
    python brain_quality.py prune --below 20   # Remove low-quality entries

*430 lines*

### class `QualityScorer`

Scores brain entries on a 0-100 scale.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `brain` |  |
| `score_entry` | `entry, all_entries` | Score a single entry. Returns breakdown + total. |
| `score_all` | `` | Score all brain entries. |

### class `DuplicateDetector`

Detects duplicate and near-duplicate brain entries.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `brain` |  |
| `find_duplicates` | `threshold` | Find all duplicate pairs above threshold. |
| `dedupe` | `threshold, dry_run` | Remove duplicates, keeping the higher-quality entry. |

### class `ProvenanceTracker`

Track entry provenance ‚Äî who added, usage count, last accessed.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `brain` |  |
| `save` | `` |  |
| `record_access` | `entry_id, accessor` | Record that an entry was accessed. |
| `record_creation` | `entry_id, creator` | Record who created an entry. |
| `get_provenance` | `entry_id` |  |
| `report` | `` | Summary provenance report. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `quality_report` | `brain` | Generate a full quality report. |
| `main` | `` |  |

---

## `tools/brain_search.py`

Brain Semantic Search Engine
============================
Advanced search capabilities for the MyWork-AI Brain using TF-IDF and fuzzy matching.

Usage:
    python brain_search.py "deployment patterns" --type pattern --status TESTED
    python brain_search.py "api" --fuzzy --limit 5
    python brain_search.py --tags python,docker --since 2026-01-01
    python brain_search.py --interactive

Features:
- TF-IDF scoring for semantic relevance
- Fuzzy matching for typos and partial matches
- Search by content, tags, type, date range, status
- Interactive search mode
- Relevance ranking and scoring
- Search result caching for performance

*468 lines*

### class `TFIDFSearchEngine`

TF-IDF based search engine for brain entries.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `brain_manager` |  |
| `search` | `query, limit` | Search using TF-IDF scoring. |

### class `FuzzyMatcher`

Fuzzy string matching for handling typos and partial matches.

| Method | Args | Description |
|--------|------|-------------|
| `similarity_ratio` | `a, b` | Calculate similarity ratio between two strings. |
| `fuzzy_search` | `cls, query, entries, threshold` | Fuzzy search across all entry text. |

### class `AdvancedBrainSearch`

Advanced search engine combining multiple search strategies.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `search` | `query, entry_type, status, tags, since` | Advanced search with multiple filters and ranking. |
| `get_search_suggestions` | `partial_query` | Get search suggestions based on partial query. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `print_search_results` | `results, query, show_scores` | Print search results with improved formatting. |
| `interactive_search` | `` | Interactive search mode with live suggestions. |
| `main` | `` | Main entry point. |

---

## `tools/brain_semantic.py`

Brain Semantic Search ‚Äî Phase 9: Brain Intelligence
====================================================
Adds embedding-based semantic search, deduplication, and quality scoring
to the Brain knowledge vault.

Uses TF-IDF + cosine similarity for zero-dependency semantic search.
No API keys needed ‚Äî runs fully offline.

Usage:
    python brain_semantic.py search <query>         # Semantic search
    python brain_semantic.py dedupe [--dry-run]     # Find duplicates
    python brain_semantic.py score                  # Quality score all entries
    python brain_semantic.py provenance <id>        # Show entry provenance
    python brain_semantic.py reindex                # Rebuild search index

*382 lines*

### class `SearchIndex`

TF-IDF search index for brain entries.

| Method | Args | Description |
|--------|------|-------------|
| `build` | `entries` | Build index from entries. |
| `search` | `query, top_k, min_score` | Search entries by semantic similarity. |
| `find_duplicates` | `threshold` | Find duplicate/near-duplicate entries. |
| `save` | `path` | Save index metadata (not vectors, those are rebuilt). |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `tokenize` | `text` | Tokenize text into lowercase words, removing stop words. |
| `compute_tf` | `tokens` | Term frequency (normalized). |
| `compute_idf` | `documents` | Inverse document frequency. |
| `tfidf_vector` | `tf, idf` | TF-IDF vector for a document. |
| `cosine_similarity` | `v1, v2` | Cosine similarity between two sparse vectors. |
| `load_brain_entries` | `` | Load all brain entries from JSON. |
| `entry_text` | `entry` | Combine entry fields into searchable text. |
| `quality_score` | `entry` | Score an entry's quality on multiple dimensions (0-100). |
| `load_provenance` | `` | Load provenance data. |
| `save_provenance` | `data` | Save provenance data. |
| `track_provenance` | `entry_id, action, actor, details` | Record a provenance event for an entry. |
| `get_provenance` | `entry_id` | Get provenance history for an entry. |
| `main` | `` |  |

---

## `tools/brain_sync.py`

Brain Sync Tool
===============
Sync local Brain entries to the Marketplace Brain API.

Usage:
    python tools/brain_sync.py export
    python tools/brain_sync.py push

Environment:
    MARKETPLACE_BRAIN_URL   (default: https://mywork-ai-production.up.railway.app/api/brain)
    MARKETPLACE_BRAIN_TOKEN (required for push; Clerk JWT bearer token)

*198 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `export_payload` | `` |  |
| `push_entries` | `` |  |
| `main` | `` |  |

---

## `tools/config.py`

MyWork Framework Configuration
==============================
Shared configuration module for all MyWork tools.
Handles dynamic path detection and environment variables.

*166 lines*

### class `Colors`

ANSI color codes for terminal output.

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_mywork_root` | `` | Detect MyWork root directory. |
| `get_autocoder_root` | `` | Get Autocoder installation directory. |
| `ensure_directories` | `` | Ensure all required directories exist. |
| `get_project_path` | `project_name` | Get path to a specific project. |
| `list_projects` | `` | List all projects in the projects directory. |
| `color` | `text, color_code` | Apply color to text for terminal output. |
| `print_success` | `msg` | Print success message in green. |
| `print_error` | `msg` | Print error message in red. |
| `print_warning` | `msg` | Print warning message in yellow. |
| `print_info` | `msg` | Print info message in blue. |
| `print_header` | `msg` | Print header message in bold. |

---

## `tools/credits_ledger.py`

Credits Ledger ‚Äî Phase 8: Payments, Credits, Escrow
Single source of truth for all financial transactions in MyWork-AI marketplace.

Supports:
- Credit purchases (Stripe or direct)
- Credit spending (marketplace purchases)
- Escrow holds and releases
- Refunds and reversals
- Full audit trail

*520 lines*

### class `TxType`(str, Enum)

### class `TxStatus`(str, Enum)

### class `LedgerEntry`

Single ledger transaction.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `user_id, tx_type, amount, description, order_id` |  |
| `to_dict` | `` |  |
| `from_dict` | `cls, d` |  |

### class `CreditsLedger`

File-backed credits ledger with full audit trail.

Every transaction is append-only with checksums for integrity.
Supports escrow, refunds, and reconciliation.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `ledger_dir` |  |
| `add_credits` | `user_id, amount, source, stripe_id, description` | Add credits to user account (purchase or bonus). |
| `spend_credits` | `user_id, amount, order_id, seller_id, item_name` | Spend credits on a marketplace purchase. Creates escrow hold for seller. |
| `release_escrow` | `order_id` | Release escrow funds to seller after escrow period. |
| `refund` | `user_id, amount, order_id, reason` | Refund credits to buyer. Cancels escrow if pending. |
| `get_balance` | `user_id` | Get current credit balance for user. |
| `get_transactions` | `user_id, limit` | Get transaction history for user. |
| `get_pending_escrows` | `` | Get all pending escrow holds (for scheduled release job). |
| `get_releasable_escrows` | `` | Get escrows ready for release (past escrow period). |
| `reconcile` | `` | Verify ledger integrity: recompute all balances from transactions. |
| `stats` | `` | Get ledger statistics. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/dep_checker.py`

Dependency Checker
==================
Check all project dependencies for outdated/vulnerable packages.

Usage:
    python3 dep_checker.py [options]
    python3 dep_checker.py --project <project-name>
    python3 dep_checker.py --help

Options:
    --project <name>    Check specific project only
    --fix              Auto-update outdated packages (use with caution)
    --security-only    Only check for security vulnerabilities
    --format json      Output in JSON format
    --help             Show this help

Examples:
    python3 dep_checker.py                    # Check all projects
    python3 dep_checker.py --project my-api   # Check specific project
    python3 dep_checker.py --security-only    # Security vulnerabilities only
    python3 dep_checker.py --fix              # Auto-update outdated packages

*555 lines*

### class `Colors`

### class `DependencyChecker`

Check project dependencies for updates and vulnerabilities.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `get_cache_file` | `key` | Get cache file path for a key. |
| `is_cache_valid` | `cache_file` | Check if cache file is still valid. |
| `get_cached_data` | `key` | Get cached data if valid. |
| `set_cached_data` | `key, data` | Store data in cache. |
| `check_python_packages` | `requirements_file` | Check Python packages for updates and vulnerabilities. |
| `get_pypi_package_info` | `package_name` | Get package info from PyPI API. |
| `check_python_vulnerabilities` | `package_name, version` | Check for known vulnerabilities (simplified). |
| `check_nodejs_packages` | `package_json_path` | Check Node.js packages for updates and vulnerabilities. |
| `check_project_dependencies` | `project_path` | Check all dependencies for a single project. |
| `print_project_results` | `results, security_only` | Print results for a single project. |
| `fix_outdated_packages` | `project_path, results` | Attempt to fix outdated packages. |
| `check_all_projects` | `security_only, fix_mode` | Check dependencies for all projects. |
| `print_summary` | `all_results, security_only` | Print overall summary. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `color` | `text, color_code` | Apply color to text. |
| `main` | `` | Main entry point. |

---

## `tools/deploy.py`

Deploy Helper
=============
One-command deploy to various platforms (Vercel, Railway, Render).
Auto-detects project type and generates appropriate config files.

Usage:
    python deploy.py <project_path> --platform vercel      # Deploy to Vercel
    python deploy.py <project_path> --platform railway     # Deploy to Railway
    python deploy.py <project_path> --platform render      # Deploy to Render
    python deploy.py --current --platform vercel           # Deploy current directory
    mw deploy <project> --platform vercel                  # Via CLI

*615 lines*

### class `ProjectDeployHelper`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_path` |  |
| `detect_project_type` | `` | Detect project type, framework, and language. |
| `generate_vercel_config` | `project_info` | Generate vercel.json configuration. |
| `generate_railway_config` | `project_info` | Generate Railway configuration files. |
| `generate_render_config` | `project_info` | Generate render.yaml configuration. |
| `create_config_files` | `platform, project_info` | Create configuration files for the specified platform. |
| `check_deployment_readiness` | `project_info` | Check if project is ready for deployment. |
| `get_deployment_instructions` | `platform, project_info` | Get deployment instructions for the platform. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `print_project_info` | `project_info` | Print detected project information. |
| `main` | `` | Main function. |

---

## `tools/doc_generator.py`

MyWork AI Documentation Generator.

Scans a project directory and auto-generates comprehensive documentation:
- README.md with project overview, install, usage
- API.md for HTTP endpoints (FastAPI/Flask/Express detection)
- MODULES.md for Python module documentation
- ARCHITECTURE.md for project structure overview

*469 lines*

### class `Colors`

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `scan_python_module` | `filepath` | Extract docstrings, classes, functions from a Python file. |
| `detect_framework` | `project_path` | Detect project framework and tech stack. |
| `scan_api_routes` | `project_path` | Detect API routes from FastAPI/Flask/Express files. |
| `generate_tree` | `project_path, max_depth, prefix` | Generate a directory tree string. |
| `generate_readme` | `project_path, info, modules, routes` | Generate README.md content. |
| `generate_api_doc` | `routes` | Generate API.md from detected routes. |
| `generate_modules_doc` | `modules, project_path` | Generate MODULES.md with detailed module documentation. |
| `run_docs` | `args` | Main entry point for docs command. |

---

## `tools/e2e/run_all_tests.py`

E2E Test: Full Test Suite Runner
===============================
Runs pytest on tests/ directory and all e2e tests.
Aggregates results into comprehensive reports.

*433 lines*

### class `TestSuiteRunner`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_root` |  |
| `log_result` | `test_name, status, message, details` | Log a test result |
| `run_command` | `cmd, timeout, cwd` | Run a command and return result |
| `run_pytest` | `` | Run pytest on the tests/ directory |
| `run_e2e_tests` | `` | Run all E2E test files |
| `run_smoke_tests` | `` | Run existing smoke tests |
| `generate_comprehensive_report` | `pytest_results, e2e_results, smoke_results` | Generate comprehensive test report |
| `generate_markdown_report` | `report, file_path` | Generate markdown report |
| `run_all_tests` | `` | Run all tests and generate reports |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point |

---

## `tools/e2e/test_autoforge.py`

E2E Test: AutoForge Integration Test
===================================
Tests autoforge_api.py imports, basic functions, backwards compatibility,
and CLI commands (mw af status, mw ac status alias).

*361 lines*

### class `AutoForgeIntegrationTester`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_root` |  |
| `log_result` | `test_name, status, message, output` | Log a test result |
| `run_command` | `cmd, timeout, cwd` | Run a command and return result |
| `test_file_existence` | `` | Test if AutoForge files exist |
| `test_autoforge_api_imports` | `` | Test if autoforge_api.py can be imported |
| `test_autoforge_api_direct` | `` | Test running autoforge_api.py directly |
| `test_backwards_compatibility` | `` | Test backwards compatibility with autocoder_api.py |
| `test_mw_af_commands` | `` | Test mw af commands |
| `test_mw_ac_alias` | `` | Test mw ac commands (legacy alias) |
| `test_autoforge_service` | `` | Test autoforge_service.py if it exists |
| `test_integration_workflow` | `` | Test a basic integration workflow |
| `run_all_tests` | `` | Run all AutoForge integration tests |
| `generate_report` | `` | Generate test report |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point |

---

## `tools/e2e/test_brain_e2e.py`

E2E Test: Brain Full Lifecycle Tester
=====================================
Tests: add entry ‚Üí search ‚Üí update ‚Üí export ‚Üí backup ‚Üí restore ‚Üí verify
Tests all entry types and brain functionality with data integrity verification.

*434 lines*

### class `BrainE2ETester`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_root` |  |
| `log_result` | `test_name, status, message, output` | Log a test result |
| `run_brain_command` | `script, args, timeout` | Run a brain command and return result |
| `test_setup` | `` | Test if all brain scripts exist |
| `test_brain_stats_initial` | `` | Test initial brain stats |
| `test_add_entries` | `` | Test adding all types of entries |
| `test_search_entries` | `added_entries` | Test searching for added entries |
| `test_update_entry` | `added_entries` | Test updating an entry |
| `test_export_functionality` | `` | Test export in different formats |
| `test_backup_restore` | `` | Test backup and restore functionality |
| `test_brain_graph` | `` | Test brain_graph.py functionality |
| `test_brain_learner` | `` | Test brain_learner.py functionality |
| `test_data_integrity` | `` | Verify data integrity after all operations |
| `run_all_tests` | `` | Run all brain E2E tests |
| `generate_report` | `` | Generate test report |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point |

---

## `tools/e2e/test_gsd.py`

E2E Test: GSD Workflow Tester
============================
Tests the mw CLI commands: status, help, dashboard, search, projects
Verifies output format, content, and error handling.

*270 lines*

### class `GSDWorkflowTester`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_root` |  |
| `log_result` | `test_name, status, message, output` | Log a test result |
| `run_mw_command` | `args, timeout` | Run a mw command and return result |
| `test_mw_status` | `` | Test mw status command |
| `test_mw_help` | `` | Test mw help command |
| `test_mw_dashboard_check` | `` | Test mw dashboard command (just check if it starts properly) |
| `test_mw_search` | `` | Test mw search command |
| `test_mw_projects` | `` | Test mw projects command |
| `test_mw_brain_status` | `` | Test mw brain commands |
| `test_error_handling` | `` | Test error handling with bad inputs |
| `test_autoforge_compatibility` | `` | Test AutoForge commands (backwards compatibility) |
| `run_all_tests` | `` | Run all GSD workflow tests |
| `generate_report` | `` | Generate test report |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point |

---

## `tools/e2e/test_health.py`

E2E Test: Health Check Validator
===============================
Tests tools/health_check.py quick and report modes.
Verifies all checks pass or documents failures.

*354 lines*

### class `HealthCheckTester`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_root` |  |
| `log_result` | `test_name, status, message, output` | Log a test result |
| `run_health_command` | `args, timeout` | Run health_check.py command and return result |
| `parse_health_output` | `output` | Parse health check output and extract status information |
| `test_health_script_exists` | `` | Test if health_check.py script exists |
| `test_health_help` | `` | Test health check help command |
| `test_health_quick` | `` | Test health check quick mode |
| `test_health_report` | `` | Test health check report mode |
| `test_health_fix_mode` | `` | Test health check fix mode if available |
| `test_health_json_output` | `` | Test if health check supports JSON output |
| `test_health_verbose_mode` | `` | Test health check verbose mode |
| `run_all_tests` | `` | Run all health check tests |
| `generate_report` | `` | Generate test report |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point |

---

## `tools/e2e/test_marketplace_e2e.py`

E2E Test: Marketplace Smoke Tests
=================================
Tests live endpoints for frontend and backend services.
Verifies response codes, content types, broken links, response times, and SSL certificates.

*444 lines*

### class `MarketplaceE2ETester`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `log_result` | `test_name, status, message, details` | Log a test result |
| `make_request` | `url, method` | Make HTTP request with error handling and timing |
| `test_ssl_certificate` | `hostname` | Test SSL certificate validity |
| `test_frontend_endpoints` | `` | Test frontend endpoints |
| `test_backend_endpoints` | `` | Test backend API endpoints |
| `test_performance` | `` | Test response times for key endpoints |
| `test_broken_links` | `` | Check for obvious broken links in homepage |
| `test_ssl_certificates` | `` | Test SSL certificates for both domains |
| `run_all_tests` | `` | Run all marketplace smoke tests |
| `generate_report` | `` | Generate test report |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point |

---

## `tools/error_handling_improvements.py`

Error Handling Improvements for MyWork-AI
=========================================

This module provides enhanced error handling with user-friendly messages
and actionable guidance for common issues discovered in batch 3 testing.

Author: Subagent for OpenClaw
Created: 2026-02-09

*239 lines*

### class `MyWorkErrorHandler`

Enhanced error handling with user-friendly messages

| Method | Args | Description |
|--------|------|-------------|
| `check_permissions` | `path` | Check if we have read/write permissions to a path |
| `check_disk_space` | `path, required_mb` | Check if we have enough disk space for operations |
| `handle_file_operation_error` | `operation, file_path, error` | Generate helpful error messages for file operation failures |
| `safe_file_write` | `file_path, content, backup` | Safely write to a file with proper error handling |
| `format_error_message` | `title, message, suggestions` | Format a consistent error message with suggestions |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `enhanced_error_decorator` | `func` | Decorator to add enhanced error handling to functions |

---

## `tools/health_check.py`

MyWork Framework Health Check
==============================
Comprehensive diagnostics for all framework components.

Usage:
    python health_check.py              # Full health check
    python health_check.py quick        # Quick status check
    python health_check.py fix          # Auto-fix common issues
    python health_check.py report       # Generate detailed report

Checks:
    - GSD installation and version
    - AutoForge server status
    - n8n connection and workflows
    - Project structure integrity
    - Git repository integrity
    - API key validity
    - Dependency versions
    - Disk space
    - Security issues

*1282 lines*

### class `HealthCheckLock`

Context manager for preventing concurrent health check runs.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `lock_file, timeout` |  |

### class `Status`(Enum)

### class `CheckResult`

### class `HealthChecker`

Performs health checks on MyWork framework components.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `add_result` | `result` |  |
| `run_all` | `` | Run all health checks. |
| `run_quick` | `` | Run quick status checks only. |
| `check_gsd` | `quick` | Check GSD installation and status. |
| `check_autoforge` | `quick` | Check AutoForge installation and server status. |
| `check_n8n` | `quick` | Check n8n-mcp and n8n-skills. |
| `check_projects` | `` | Check project structure and GSD state. |
| `check_api_keys` | `` | Check API key configuration. |
| `check_dependencies` | `` | Check Python and Node.js dependencies. |
| `check_security` | `` | Check for common security issues. |
| `check_disk_space` | `` | Check available disk space. |
| `check_git_integrity` | `` | Check git repository integrity. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `check_file_permissions` | `path, need_write` | Check if we have required permissions for file/directory operations. |
| `safe_socket_connect` | `host, port, timeout` | Safely check if a socket connection can be established with timeout protection. |
| `print_results` | `results, verbose` | Print formatted health check results. |
| `auto_fix` | `results` | Attempt to auto-fix issues. |
| `generate_report` | `results` | Generate a detailed markdown report. |
| `main` | `` | Main entry point. |

---

## `tools/lint_watcher.py`

Lint Scheduler Manager - Control the scheduled linting runner
Part of the MyWork Framework

Usage:
    python tools/lint_watcher.py start    # Start scheduler in background
    python tools/lint_watcher.py stop     # Stop running scheduler
    python tools/lint_watcher.py status   # Check if running
    python tools/lint_watcher.py restart  # Restart scheduler
    python tools/lint_watcher.py logs     # Show recent logs

*201 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_pid` | `` | Get the PID of the running agent |
| `is_running` | `pid` | Check if a process is running |
| `start` | `` | Start the lint scheduler in the background |
| `stop` | `` | Stop the lint scheduler |
| `status` | `` | Check the status of the lint scheduler |
| `restart` | `` | Restart the lint scheduler |
| `logs` | `` | Show the logs |
| `main` | `` | Main CLI entry point |

---

## `tools/marketplace_upload_previews.py`

Upload SportsAI preview images to Marketplace via presigned URLs and
attach them to the product listing.

Requires:
  - MARKETPLACE_TOKEN (Clerk JWT)
Optional:
  - MARKETPLACE_API_URL (default: https://mywork-ai-production.up.railway.app)
  - MARKETPLACE_PRODUCT_ID (default: SportsAI ID)
  - PREVIEW_DIR (default: assets/screenshots/sportsai)

*128 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/module_registry.py`

Auto-Learning Module Registry for MyWork Framework
===================================================
Scans all projects for reusable components, patterns, and modules.
Enables cross-project search to reduce rebuild time.

Usage:
    python module_registry.py scan           # Scan all projects and update registry
    python module_registry.py search <query> # Search for modules/patterns
    python module_registry.py list [type]    # List all registered modules
    python module_registry.py show <id>      # Show module details
    python module_registry.py stats          # Show registry statistics
    python module_registry.py export         # Export registry to markdown

Module Types:
    - api_endpoint: REST/GraphQL endpoints
    - component: UI components (React, Vue, etc.)
    - service: Backend services/classes
    - utility: Helper functions
    - schema: Database models/schemas
    - workflow: n8n workflows
    - hook: React hooks, Git hooks
    - middleware: Express/FastAPI middleware
    - config: Configuration patterns
    - integration: External API integrations

*865 lines*

### class `Module`

Represents a discovered module.

| Method | Args | Description |
|--------|------|-------------|
| `to_dict` | `` |  |

### class `ModuleRegistry`

Registry for all discovered modules across projects.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `root` |  |
| `load` | `` | Load registry from file. |
| `save` | `` | Save registry to file. |
| `add_module` | `module` | Add or update a module in the registry. |
| `search` | `query, type_filter, include_brain, include_files, max_results` | Enhanced search across modules, brain entries, and project files. |
| `get_by_type` | `module_type` | Get all modules of a specific type. |
| `get_by_project` | `project` | Get all modules in a project. |
| `get_stats` | `` | Get registry statistics. |

### class `ProjectScanner`

Scans projects for modules and patterns.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `registry` |  |
| `scan_all_projects` | `` | Scan all projects in the projects directory. |
| `scan_project` | `project_path` | Scan a single project for modules. |
| `scan_file` | `file_path, project, language` | Scan a single file for modules. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `print_search_results` | `modules, query` | Print formatted search results. |
| `print_stats` | `stats` | Print registry statistics. |
| `export_to_markdown` | `registry` | Export registry to markdown file. |
| `main` | `` | Main entry point. |

---

## `tools/mw.py`

MyWork Command Line Interface (mw)
==================================
Unified interface for all MyWork framework tools.

Usage:
    mw <command> [options]

Commands:
    dashboard       Interactive framework dashboard with metrics and status
    status          Quick health check of all components
    setup           First-time setup wizard for new users
    guide           Interactive workflow guide and tutorial
    update          Check and apply updates (GSD, AutoForge, n8n)
    search <query>  Search module registry for reusable code
    new <name>      Create a new project (see: mw new --help)
    prompt-enhance  Enhance rough prompts for GSD planning
    scan            Scan all projects and update module registry
    fix             Auto-fix common issues
    report          Generate detailed health report
    doctor          Full system diagnostics
    ecosystem       Show all live app URLs and ecosystem overview
    marketplace     Open marketplace information and links
    links           Show all useful framework links

Project Commands:
    mw projects     List all projects (uses project registry if available)
    mw projects scan    Refresh project registry
    mw projects export  Export project registry to markdown
    mw open <name>  Open project in VS Code
    mw cd <name>    Print cd command for project

AutoForge Commands:
    mw af start <project>    Start AutoForge for project
    mw af stop <project>     Stop AutoForge
    mw af pause <project>    Pause AutoForge
    mw af resume <project>   Resume AutoForge
    mw af status             Check AutoForge status
    mw af progress <project> Show AutoForge progress
    mw af list               List AutoForge projects
    mw af ui                 Open AutoForge UI
    mw af service <command>  Manage AutoForge service (macOS)

Legacy Commands (deprecated but supported):
    mw ac <subcommand>       Alias for AutoForge commands (backwards compatibility)

n8n Commands:
    mw n8n list              List n8n workflows
    mw n8n status            Check n8n connection

Brain Commands:
    mw brain search <query>  Search knowledge vault
    mw brain add <content>   Quick add a lesson
    mw brain review          Show entries needing attention
    mw brain stats           Brain statistics
    mw brain learn           Discover new learnings automatically
    mw brain learn-deep      Weekly deep analysis

Lint Commands:
    mw lint scan             Scan all files for linting issues
    mw lint scan --file X    Scan specific file
    mw lint scan --dir X     Scan specific directory
    mw lint watch            Watch files and auto-lint changes
    mw lint fix              Fix all linting issues
    mw lint config --show    Show current linting configuration
    mw lint config --edit    Edit linting configuration
    mw lint stats            Show linting statistics

Code Review & Quality Commands:
    mw review <file>         AI-powered code review of specific file
    mw review --diff         Review current git diff
    mw review --staged       Review staged changes
    mw docs generate <proj>  Generate AI documentation for project
    mw health <project>      Score project health (0-100)
    mw deploy <proj> --platform <vercel|railway|render>  Deploy project

Examples:
    mw setup                 # First-time setup wizard
    mw guide                 # Learn the MyWork workflow
    mw status                # Quick health overview  
    mw search "auth"         # Find authentication modules
    mw new my-app fastapi    # Create FastAPI project
    mw prompt-enhance "build a todo app"  # Enhance prompts for GSD
    mw af start my-app       # Start AutoForge
    mw lint watch            # Auto-fix linting as you code
    mw review main.py        # AI code review
    mw docs generate my-app  # Generate documentation
    mw health my-app         # Check project health
    mw deploy my-app --platform vercel  # Deploy to Vercel

*2846 lines*

### class `Colors`

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `color` | `text, color_code` | Apply color to text. |
| `validate_input` | `value, name, max_length, allow_empty, allow_paths` | Validate user input for security and correctness. |
| `validate_project_name` | `name` | Validate project name according to MyWork conventions. |
| `run_tool` | `tool_name, args` | Run a MyWork tool with arguments. |
| `cmd_status` | `args` | Run a quick health check of all MyWork framework components. |
| `cmd_update` | `args` | Check and apply updates for GSD, AutoForge, and n8n components. |
| `cmd_search` | `args` | Search the module registry for reusable code components. |
| `cmd_new` | `args` | Create new project. |
| `cmd_scan` | `` | Scan projects for modules. |
| `cmd_fix` | `` | Auto-fix issues. |
| `cmd_report` | `` | Generate health report. |
| `cmd_doctor` | `` | Full system diagnostics. |
| `cmd_dashboard` | `args` | Interactive framework dashboard with metrics and status. |
| `cmd_projects` | `` | List all projects. |
| `cmd_project_health` | `project_name` | Check health of a specific project. |
| `tick_cross` | `condition` | Return colored tick or cross based on condition. |
| `cmd_open` | `args` | Open project in VS Code. |
| `cmd_cd` | `args` | Print cd command for project. |
| `cmd_autoforge` | `args` | AutoForge commands. |
| `cmd_n8n` | `args` | n8n commands. |
| `cmd_brain` | `args` | Brain knowledge vault commands. |
| `is_auto_linter_running` | `` | Check if auto-lint scheduler is currently running. |
| `cmd_credits` | `args` | Credits ledger management ‚Äî Phase 8 Payments. |
| `cmd_lint` | `args` | Auto-linting commands. |
| `cmd_ecosystem` | `args` | Show all live app URLs and ecosystem overview. |
| `cmd_marketplace_info` | `args` | Open marketplace information and links. |
| `cmd_links` | `args` | Show all useful framework links. |
| `cmd_setup` | `args` | Setup command for first-time users. |
| `cmd_guide` | `args` | Interactive guide showing the full workflow. |
| `cmd_prompt_enhance` | `args` | Enhance user prompts for GSD. |
| `cmd_init` | `args` | Initialize current directory as a MyWork project. |
| `cmd_stats` | `args` | Show framework-wide statistics. |
| `cmd_clean` | `args` | Clean temporary files across all projects. |
| `cmd_backup` | `args` | Backup all projects and brain data. |
| `cmd_changelog` | `args` | Generate changelog from git commits. |
| `cmd_analytics_wrapper` | `args` | Run project analytics. |
| `print_help` | `` | Print help message. |
| `cmd_docs` | `args` | Auto-generate documentation for a project. |
| `cmd_version` | `` | Show framework version, Python version, and platform info. |
| `main` | `` | Main entry point. |

---

## `tools/n8n_api.py`

Tool: n8n API Client
Purpose: Create, manage, and execute n8n workflows via REST API

Usage:
    python tools/n8n_api.py --action list
    python tools/n8n_api.py --action get --workflow-id "abc123"
    python tools/n8n_api.py --action create --workflow-file "workflow.json"
    python tools/n8n_api.py --action activate --workflow-id "abc123"
    python tools/n8n_api.py --action execute --workflow-id "abc123" --data '{"key": "value"}'

Environment Variables Required:
    - N8N_API_URL: n8n instance URL (e.g., https://seme.app.n8n.cloud)
    - N8N_API_KEY: API key for authentication

*515 lines*

### class `HttpRequestError`(Exception)

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `status_code, message, response_text` |  |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `get_headers` | `` | Return headers for n8n API requests. |
| `list_workflows` | `active_only` | List all workflows. |
| `get_workflow` | `workflow_id` | Get a specific workflow by ID. |
| `create_workflow` | `workflow_data` | Create a new workflow. |
| `update_workflow` | `workflow_id, workflow_data` | Update an existing workflow. |
| `delete_workflow` | `workflow_id` | Delete a workflow. |
| `activate_workflow` | `workflow_id` | Activate a workflow. |
| `deactivate_workflow` | `workflow_id` | Deactivate a workflow. |
| `execute_workflow` | `workflow_id, data` | Execute a workflow with optional input data. |
| `trigger_webhook` | `webhook_path, data, method` | Trigger a webhook workflow. |
| `list_executions` | `workflow_id, status` | List workflow executions. |
| `health_check` | `` | Perform a lightweight API check to verify connectivity and auth. |
| `main` | `` |  |

---

## `tools/perfect_auto_agent.py`

Perfect Auto-Linting Agent - NEVER SLEEPS!
Forces immediate markdown fixing without any delays.

*84 lines*

### class `PerfectMarkdownHandler`(FileSystemEventHandler)

Immediately fixes ANY markdown file that changes

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `on_modified` | `event` |  |
| `on_created` | `event` |  |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Start the perfect agent that NEVER sleeps |

---

## `tools/project_archive.py`

Project Archiver
================
Archive a project to zip with metadata.

Usage:
    python3 project_archive.py <project-name> [options]
    python3 project_archive.py --help

Options:
    --output <path>      Output archive path (default: ./archives/)
    --include-git        Include .git directory in archive
    --exclude <pattern>  Exclude files matching pattern (can be used multiple times)
    --compress-level <n> Compression level 0-9 (default: 6)
    --metadata-only      Only generate metadata, don't create archive
    --help               Show this help

Examples:
    python3 project_archive.py my-api
    python3 project_archive.py blog-platform --output /backups/
    python3 project_archive.py my-app --include-git --compress-level 9
    python3 project_archive.py test-project --exclude "*.log" --exclude "node_modules"

*522 lines*

### class `Colors`

### class `ProjectArchiver`

Archive projects with comprehensive metadata.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `should_exclude` | `file_path, custom_excludes` | Check if a file should be excluded from the archive. |
| `calculate_file_hash` | `file_path` | Calculate SHA256 hash of a file. |
| `get_git_info` | `project_path` | Get git repository information. |
| `get_project_dependencies` | `project_path` | Get project dependencies information. |
| `analyze_project_structure` | `project_path, include_git, custom_excludes` | Analyze project structure and generate metadata. |
| `create_archive` | `project_path, output_path, include_git, custom_excludes, compression_level` | Create project archive with metadata. |
| `generate_metadata_only` | `project_path, output_path, include_git, custom_excludes` | Generate only metadata without creating archive. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `color` | `text, color_code` | Apply color to text. |
| `resolve_project_path` | `project_name` | Resolve project name to full path. |
| `main` | `` | Main entry point. |

---

## `tools/project_compare.py`

Project Comparison Tool
======================
Compare two projects side by side (file count, test count, dependencies, size).

Usage:
    python3 project_compare.py <project1> <project2>
    python3 project_compare.py --help

Examples:
    python3 project_compare.py my-api blog-platform
    python3 project_compare.py ../project1 /path/to/project2

*413 lines*

### class `Colors`

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `color` | `text, color_code` | Apply color to text. |
| `analyze_project` | `project_path` | Analyze a single project and return metrics. |
| `format_number` | `num` | Format number with commas. |
| `format_size` | `size_mb` | Format size in human readable format. |
| `print_comparison` | `project1, project2` | Print detailed comparison of two projects. |
| `resolve_project_path` | `project_name` | Resolve project name to full path. |
| `main` | `` | Main entry point. |

---

## `tools/project_health.py`

Project Health Scorer
=====================
Analyzes a project and scores its health based on various criteria.

Scoring Criteria (Total: 100 points):
- Has README (10 points)
- Has tests (15 points)
- Has CI/CD config (10 points)
- Code quality (20 points)
- Documentation (15 points)
- Security (15 points)
- Dependencies up to date (15 points)

Usage:
    python project_health.py <project_path>     # Score specific project
    python project_health.py --current          # Score current directory
    mw health <project>                          # Via CLI

*731 lines*

### class `ProjectHealthScorer`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `project_path` |  |
| `analyze` | `` | Run complete project health analysis. |
| `check_readme` | `` | Check for README file (10 points). |
| `check_tests` | `` | Check for tests (15 points). |
| `check_ci_cd` | `` | Check for CI/CD configuration (10 points). |
| `check_code_quality` | `` | Check code quality indicators (20 points). |
| `check_documentation` | `` | Check for documentation (15 points). |
| `check_security` | `` | Check for security measures (15 points). |
| `check_dependencies` | `` | Check if dependencies are up to date (15 points). |
| `get_health_rating` | `percentage` | Get health rating based on percentage score. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `print_results` | `results` | Print formatted results. |
| `main` | `` | Main function. |

---

## `tools/project_registry.py`

Project Registry Tool
=====================
Indexes project metadata (project.yaml) for MyWork.

Usage:
    python tools/project_registry.py scan
    python tools/project_registry.py list
    python tools/project_registry.py show <project-name>
    python tools/project_registry.py stats
    python tools/project_registry.py export

*332 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `scan_projects` | `` |  |
| `load_registry` | `` |  |
| `format_flags` | `entry` |  |
| `cmd_list` | `` |  |
| `cmd_show` | `args` |  |
| `cmd_stats` | `` |  |
| `cmd_export` | `` |  |
| `main` | `` |  |

---

## `tools/qa/check_backend_health.py`

Automated backend QA checks for the Marketplace API.

*107 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `run_check` | `label, path, expect_json, expected_subset` |  |
| `main` | `` |  |

---

## `tools/qa/check_frontend_routes.py`

Automated frontend QA checks for the Marketplace UI.

*100 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `check_route` | `path, label` |  |
| `main` | `` |  |

---

## `tools/scaffold.py`

Project Scaffolding Tool for MyWork Framework
==============================================
Quickly create new projects with pre-configured templates.

Usage:
    python scaffold.py new <name> [template]   # Create new project
    python scaffold.py list                    # List available templates
    python scaffold.py from-module <name> <module_id>  # Create from registry module

Templates:
    - basic: Empty project with GSD structure
    - fastapi: FastAPI backend with SQLite
    - nextjs: Next.js frontend with TypeScript
    - fullstack: FastAPI backend + Next.js frontend
    - cli: Python CLI application
    - automation: n8n + Python automation project

*4875 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `create_structure` | `path, structure, context` | Recursively create directory structure. |
| `create_project` | `name, template` | Create a new project from template. |
| `list_templates` | `` | List available templates. |
| `main` | `` | Main entry point. |

---

## `tools/security/api_tester.py`

API Security Tester
====================
Tests API endpoints for common security vulnerabilities.

*465 lines*

### class `APISecurityFinding`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `endpoint, method, severity, issue, details` |  |
| `to_dict` | `` |  |

### class `APISecurityTester`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `base_url` |  |
| `make_request` | `url, method, data, headers, timeout` | Make HTTP request and return status code, headers, and body. |
| `test_endpoint_discovery` | `` | Test for exposed endpoints and information disclosure. |
| `test_security_headers` | `` | Test for security headers. |
| `test_cors` | `` | Test CORS configuration. |
| `test_sql_injection` | `` | Test for SQL injection vulnerabilities. |
| `test_xss` | `` | Test for XSS vulnerabilities. |
| `test_rate_limiting` | `` | Test for rate limiting. |
| `test_https_redirect` | `` | Test if HTTP redirects to HTTPS. |
| `run_all_tests` | `` | Run all security tests. |
| `generate_report` | `` | Generate API security test report. |
| `save_results` | `output_path` | Save test results to JSON file. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/security/code_scanner.py`

Code Security Scanner
=====================
Scans all Python files in the repository for security vulnerabilities.

*282 lines*

### class `SecurityFinding`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `severity, file_path, line_num, description, code_snippet` |  |
| `to_dict` | `` |  |

### class `CodeSecurityScanner`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `repo_path` |  |
| `scan_file` | `file_path` | Scan a single Python file for security issues. |
| `scan_repository` | `` | Scan all Python files in the repository. |
| `generate_report` | `` | Generate a security report. |
| `save_results` | `output_path` | Save scan results to JSON file. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/security/dep_audit.py`

Dependency Security Auditor
============================
Checks package dependencies for known vulnerabilities and outdated versions.

*357 lines*

### class `DependencyFinding`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `package, version, severity, issue, recommendation` |  |
| `to_dict` | `` |  |

### class `DependencyAuditor`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `repo_path` |  |
| `parse_requirements_txt` | `file_path` | Parse requirements.txt file and extract package names and versions. |
| `parse_setup_py` | `file_path` | Parse setup.py file and extract dependencies. |
| `check_pip_audit` | `` | Try to use pip-audit if available. |
| `check_pypi_latest` | `package_name, current_version` | Check PyPI for the latest version of a package. |
| `version_compare` | `version1, version2` | Compare two version strings. Returns -1 if v1 < v2, 0 if equal, 1 if v1 > v2. |
| `audit_dependencies` | `` | Audit all dependencies for vulnerabilities and outdated versions. |
| `generate_report` | `` | Generate dependency audit report. |
| `save_results` | `output_path` | Save audit results to JSON file. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/security/generate_report.py`

Security Audit Report Generator
===============================
Runs all security scanners and generates a comprehensive security audit report.

*413 lines*

### class `SecurityAuditReportGenerator`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `repo_path, api_url` |  |
| `run_code_scanner` | `` | Run code security scanner. |
| `run_dependency_auditor` | `` | Run dependency auditor. |
| `run_api_tester` | `` | Run API security tester. |
| `run_infrastructure_scanner` | `` | Run infrastructure security scanner. |
| `calculate_risk_score` | `` | Calculate overall risk score based on findings. |
| `generate_executive_summary` | `` | Generate executive summary. |
| `generate_detailed_report` | `` | Generate detailed security audit report. |
| `save_consolidated_results` | `` | Save consolidated results to JSON. |
| `run_full_audit` | `` | Run complete security audit. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/security/infra_scanner.py`

Infrastructure Security Scanner
===============================
Scans local system for security configuration issues.

*458 lines*

### class `InfraSecurityFinding`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `category, severity, issue, details, recommendation` |  |
| `to_dict` | `` |  |

### class `InfrastructureScanner`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `repo_path` |  |
| `run_command` | `command` | Run a system command and return output. |
| `scan_open_ports` | `` | Scan for open ports that might be security risks. |
| `scan_file_permissions` | `` | Scan for files with insecure permissions. |
| `scan_ssh_config` | `` | Scan SSH configuration for security issues. |
| `scan_running_services` | `` | Scan for potentially risky running services. |
| `scan_git_security` | `` | Scan git configuration for security issues. |
| `scan_environment_variables` | `` | Scan for sensitive information in environment variables. |
| `scan_world_readable_files` | `` | Scan for world-readable sensitive files. |
| `run_all_scans` | `` | Run all infrastructure security scans. |
| `generate_report` | `` | Generate infrastructure security report. |
| `save_results` | `output_path` | Save scan results to JSON file. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` |  |

---

## `tools/simulation/credit_engine.py`

Virtual Credit System for MyWork-AI
Manages virtual balances, transactions, and reporting

*642 lines*

### class `TransactionType`(Enum)

### class `TransactionStatus`(Enum)

### class `Transaction`

Individual transaction record

### class `UserBalance`

User balance and credit information

### class `CreditEngine`

Main credit management system

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `max_balance, min_transaction` |  |
| `create_user_balance` | `user_id, initial_balance` | Create a new user balance record |
| `top_up` | `user_id, amount, source, reference_id` | Add credits to user balance |
| `spend` | `user_id, amount, description, reference_id` | Deduct credits from user balance |
| `transfer` | `from_user_id, to_user_id, amount, description` | Transfer credits between users |
| `earn_commission` | `user_id, amount, source, level, reference_id` | Award commission to user |
| `refund` | `user_id, amount, reason, reference_id` | Process a refund to user |
| `get_balance` | `user_id` | Get current user balance |
| `get_user_transactions` | `user_id, limit` | Get transaction history for a user |
| `freeze_account` | `user_id, reason` | Freeze user account |
| `unfreeze_account` | `user_id, reason` | Unfreeze user account |
| `get_total_circulation` | `` | Get total credits currently in circulation |
| `get_top_earners` | `limit` | Get top earners by total earnings |
| `get_transaction_volume` | `days` | Get transaction volume for specified period |
| `generate_system_report` | `` | Generate comprehensive system report |
| `export_data` | `filename` | Export all credit system data |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main function for testing the credit engine |

---

## `tools/simulation/install_simulator.py`

MyWork-AI Install Experience Simulator
======================================

Simulates the complete installation experience to identify issues and grade the process.

Tests:
1. Python version compatibility
2. Package dependencies
3. Setup wizard functionality  
4. Directory structure creation
5. Configuration file setup
6. CLI tool accessibility

Usage:
    python tools/simulation/install_simulator.py

This generates a detailed report on the installation experience.

*873 lines*

### class `InstallSimulator`

Simulates the MyWork-AI installation process.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `collect_system_info` | `` | Collect system information for the simulation. |
| `log_check` | `check_name, status, details, grade, recommendations` | Log a check result. |
| `add_issue` | `issue` | Add an issue found during simulation. |
| `run_command` | `cmd, cwd` | Run a command and return (returncode, stdout, stderr). |
| `check_python_version` | `` | Check Python version compatibility. |
| `check_pip_availability` | `` | Check if pip is available and working. |
| `check_dependencies` | `` | Check if dependencies can be installed. |
| `check_setup_wizard` | `` | Check if setup wizard functionality exists. |
| `check_directory_creation` | `` | Test that required directories can be created. |
| `check_configuration_files` | `` | Check configuration file setup. |
| `check_cli_accessibility` | `` | Check if CLI tool is accessible and working. |
| `check_install_scripts` | `` | Check installation scripts. |
| `calculate_average_grade` | `grades` | Calculate average letter grade. |
| `generate_report` | `` | Generate the installation experience report. |
| `get_improvement_areas` | `` | Get improvement areas based on failed checks. |
| `get_difficulty_level` | `grade` | Get difficulty level assessment. |
| `grade_error_handling` | `` | Grade error handling quality. |
| `grade_documentation` | `` | Grade documentation quality. |
| `estimate_success_rate` | `grade` | Estimate installation success rate. |
| `run_simulation` | `` | Run the complete installation simulation. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point. |

---

## `tools/simulation/mlm_simulator.py`

MLM/Referral Simulator for MyWork-AI
Builds referral trees and manages commission cascades

*629 lines*

### class `CommissionLevel`(Enum)

### class `ReferralNode`

Individual node in the referral tree

### class `CommissionEvent`

Commission event record

### class `MLMSimulator`

Multi-Level Marketing / Referral system simulator

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `max_levels` |  |
| `generate_referral_code` | `user_id` | Generate unique referral code for user |
| `add_user` | `user_id, referrer_code` | Add a new user to the referral tree |
| `get_upline_chain` | `user_id` | Get the upline chain for a user (up to max_levels) |
| `calculate_commissions` | `buyer_id, sale_amount, product_id` | Calculate commissions for a sale and return commission breakdown |
| `process_sale` | `buyer_id, sale_amount, product_id` | Process a sale and calculate/distribute commissions |
| `get_referral_stats` | `user_id` | Get comprehensive referral statistics for a user |
| `visualize_tree` | `root_user_id, max_depth` | Create ASCII visualization of referral tree |
| `detect_anomalies` | `` | Detect potential issues in the referral tree |
| `generate_mlm_report` | `` | Generate comprehensive MLM performance report |
| `export_data` | `filename` | Export MLM system data |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main function for testing the MLM simulator |

---

## `tools/simulation/product_simulator.py`

Product Lifecycle Simulator for MyWork-AI
Simulates full product lifecycle and webhook events

*899 lines*

### class `ProductStatus`(Enum)

### class `ProductType`(Enum)

### class `OrderStatus`(Enum)

### class `ReviewStatus`(Enum)

### class `WebhookEventType`(Enum)

### class `Product`

Product entity

### class `Order`

Order entity

### class `Review`

Product review entity

### class `WebhookEvent`

Webhook event simulation

### class `ProductLifecycleSimulator`

Main product lifecycle simulator

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `generate_realistic_product` | `seller_id, product_type` | Generate a realistic product |
| `submit_for_review` | `product_id` | Submit product for review |
| `review_product` | `product_id, approve, reason` | Review a product (admin action) |
| `activate_product` | `product_id` | Activate an approved product |
| `simulate_product_view` | `product_id` | Simulate someone viewing a product |
| `create_order` | `buyer_id, product_id` | Create an order for a product |
| `simulate_payment_success` | `order_id` | Simulate successful payment (Stripe webhook) |
| `simulate_delivery` | `order_id` | Simulate product delivery |
| `create_review` | `buyer_id, order_id, rating, title, comment` | Create a product review |
| `moderate_review` | `review_id, approve, reason` | Moderate a review |
| `process_refund` | `order_id, reason, amount` | Process a refund |
| `simulate_subscription_events` | `buyer_id, product_id` | Simulate subscription lifecycle events |
| `get_product_metrics` | `product_id` | Get comprehensive metrics for a product |
| `get_seller_dashboard` | `seller_id` | Get seller dashboard data |
| `simulate_full_lifecycle` | `seller_id, buyer_id, product_type` | Simulate a complete product lifecycle |
| `export_data` | `filename` | Export all product system data |
| `get_system_stats` | `` | Get comprehensive system statistics |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main function for testing the product lifecycle simulator |

---

## `tools/simulation/run_simulation.py`

Full Simulation Runner for MyWork-AI
Orchestrates all simulators together for comprehensive testing

*672 lines*

### class `SimulationOrchestrator`

Main orchestrator for all simulation components

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `log_step` | `step, success, details` | Log a simulation step |
| `run_scenario` | `scenario_name, scenario_func` | Run a simulation scenario and track success/failure |
| `scenario_user_registration` | `` | Scenario: Generate users with referral relationships |
| `scenario_product_listings` | `` | Scenario: Sellers list products |
| `scenario_marketplace_activity` | `` | Scenario: Simulate purchases, commissions, and credits flow |
| `scenario_refunds_processing` | `` | Scenario: Process refunds and handle credit returns |
| `scenario_system_integrity` | `` | Scenario: Verify system integrity and detect anomalies |
| `run_full_simulation` | `` | Run the complete marketplace simulation |
| `generate_comprehensive_report` | `` | Generate comprehensive simulation report |
| `save_report` | `report, filename` | Save simulation report to file |
| `generate_markdown_report` | `report` | Generate markdown format report |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main function to run the complete simulation |

---

## `tools/simulation/scenarios/batch_1_basic.py`

Batch 1: Basic Functionality Simulations (Scenarios 1-10)
=========================================================
PLACEHOLDER - These scenarios would test basic mw commands.

*39 lines*

---

## `tools/simulation/scenarios/batch_1_beginners.py`

MyWork-AI User Simulations - Batch 1: Beginner Users
====================================================

This script runs comprehensive user simulations to test the beginner experience
with MyWork-AI. Each simulation tests both happy paths and error handling to
ensure users get clear, helpful guidance when things go wrong.

Author: OpenClaw AI Subagent
Date: February 9, 2026

*820 lines*

### class `SimResult`

Results from a user simulation test.

### class `UserSimulator`

Simulates beginner user interactions with MyWork-AI.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `mywork_root` |  |
| `setup_test_environment` | `` | Create a temporary test environment. |
| `cleanup_test_environments` | `` | Clean up all test directories. |
| `run_command` | `cmd, cwd, env` | Run a command and return (returncode, stdout, stderr). |
| `grade_error_handling` | `output, stderr, returncode` | Grade the quality of error handling. |
| `sim_1_no_python` | `` | SIM 1: User has no Python installed. |
| `sim_2_wrong_python_version` | `` | SIM 2: User has old Python version (3.8). |
| `sim_3_missing_env_file` | `` | SIM 3: Fresh install ‚Äî missing .env file. |
| `sim_4_wrong_command` | `` | SIM 4: User types wrong command (typos). |
| `sim_5_invalid_project_name` | `` | SIM 5: User creates project with invalid name. |
| `sim_6_existing_project_name` | `` | SIM 6: User creates project with existing name. |
| `sim_7_autoforge_without_planning` | `` | SIM 7: User tries to run AutoForge without planning. |
| `sim_8_empty_brain_entry` | `` | SIM 8: User adds empty brain entry. |
| `sim_9_brain_search_no_entries` | `` | SIM 9: User searches brain with no entries. |
| `sim_10_wrong_directory` | `` | SIM 10: User runs commands from wrong directory. |
| `run_all_simulations` | `` | Run all 10 simulations and return results. |
| `save_results` | `output_dir` | Save simulation results to JSON and Markdown files. |
| `generate_report` | `report_file` | Generate a comprehensive markdown report. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point for running user simulations. |

---

## `tools/simulation/scenarios/batch_2_intermediate.py`

Batch 2: Intermediate User Simulations (SIM 11-20)
=================================================

This module contains 10 intermediate user simulations that test:
- Happy path, error path, error message quality, step-by-step guidance, and safety
- Real user workflows with the MyWork framework tools
- Error handling and recovery scenarios
- User experience quality

Each simulation is run with actual commands and real output is recorded.

*1606 lines*

### class `SimResult`

Result from a single simulation.

### class `Batch2IntermediateSimulator`

Batch 2 intermediate user simulations.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `mywork_root` |  |
| `simulation_11_fullstack_workflow` | `` | SIM 11: User creates fullstack project and follows the workflow. |
| `simulation_12_vague_prompt_enhance` | `` | SIM 12: User tries to enhance a vague prompt. |
| `simulation_13_detailed_prompt_enhance` | `` | SIM 13: User tries prompt-enhance with detailed input. |
| `simulation_14_brain_workflow` | `` | SIM 14: User runs brain commands in sequence. |
| `simulation_15_health_check_fix` | `` | SIM 15: User runs health check and follows fix suggestions. |
| `simulation_16_nonexistent_template` | `` | SIM 16: User tries to use non-existent template. |
| `simulation_17_projects_scan_export` | `` | SIM 17: User scans projects and exports. |
| `simulation_18_lint_commands` | `` | SIM 18: User tries lint commands. |
| `simulation_19_ctrl_c_interrupt` | `` | SIM 19: User hits Ctrl+C during long operation. |
| `simulation_20_conflicting_options` | `` | SIM 20: User provides conflicting options. |
| `run_all_simulations` | `` | Run all batch 2 simulations. |
| `save_results` | `` | Save simulation results to JSON and markdown files. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point for running batch 2 simulations. |

---

## `tools/simulation/scenarios/batch_3_advanced.py`

Batch 3: Advanced & Edge Case User Simulations (Scenarios 21-30)
================================================================

This module tests advanced edge cases, security vulnerabilities, and error conditions
that real users might encounter. All tests run actual commands and record results.

Tests include:
- SQL injection attempts
- Extremely long inputs  
- Unicode/emoji handling
- Concurrent operations
- Disk space issues
- Permission errors
- Data corruption recovery
- Network failures
- Complete end-to-end workflows
- Stress testing

Author: Subagent for OpenClaw
Created: 2026-02-09

*738 lines*

### class `TestResult`

### class `AdvancedUserSimulator`

Advanced edge case and security testing for MyWork-AI

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `workspace_root` |  |
| `run_command` | `cmd, timeout` | Run shell command and capture output |
| `scenario_21_sql_injection_test` | `` | SIM 21: Test SQL injection attempts in search |
| `scenario_22_long_input_test` | `` | SIM 22: Test extremely long inputs |
| `scenario_23_unicode_test` | `` | SIM 23: Test unicode, emoji and special character handling |
| `scenario_24_concurrent_test` | `` | SIM 24: Test concurrent operations |
| `scenario_25_disk_full_test` | `` | SIM 25: Simulate disk full conditions |
| `scenario_26_permission_test` | `` | SIM 26: Test permission error handling |
| `scenario_27_corruption_recovery_test` | `` | SIM 27: Test recovery from corrupted data files |
| `scenario_28_network_failure_test` | `` | SIM 28: Test network failure during operations |
| `scenario_29_end_to_end_workflow_test` | `` | SIM 29: Complete end-to-end user workflow |
| `scenario_30_stress_test` | `` | SIM 30: Rapid-fire stress test |
| `run_all_scenarios` | `` | Run all batch 3 scenarios and return results |
| `generate_report` | `` | Generate comprehensive test report |

---

## `tools/simulation/scenarios/run_all_scenarios.py`

Master Simulation Runner - All 30 User Scenarios
================================================

This script runs all user simulation batches and generates a comprehensive
master report with aggregated results across all scenarios.

Batches:
- Batch 1: Basic functionality (SIM 1-10) 
- Batch 2: Intermediate workflows (SIM 11-20)
- Batch 3: Advanced & Edge Cases (SIM 21-30)

Author: Subagent for OpenClaw  
Created: 2026-02-09

*505 lines*

### class `BatchResult`

### class `MasterSimulationRunner`

Orchestrates all user simulation batches and generates master report

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `run_batch_if_exists` | `batch_file, batch_name, scenario_range` | Run a batch simulation if the file exists |
| `create_placeholder_batches` | `` | Create placeholder batch files for 1 and 2 if they don't exist |
| `run_all_batches` | `` | Run all simulation batches |
| `generate_master_report` | `` | Generate comprehensive master report across all batches |
| `print_summary` | `` | Print final summary to console |

---

## `tools/simulation/test_runner.py`

Quick test runner for user journey simulation.

*27 lines*

---

## `tools/simulation/user_journey.py`

MyWork-AI Complete User Journey Simulation
==========================================

Simulates the entire user experience from signup to marketplace listing.
Tests every aspect of the user flow and generates detailed reports.

Usage:
    python tools/simulation/user_journey.py

This will run through all 7 stages:
1. Signup & Onboarding
2. CLI Experience Testing
3. Project Creation (5 different projects)
4. AutoForge Activation
5. GSD Final Audit
6. Marketplace Submission
7. Report Generation

*1522 lines*

### class `UserJourneySimulator`

Simulates the complete user journey through MyWork-AI framework.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `log_stage` | `stage, status, details, grade` | Log the completion of a stage. |
| `add_issue` | `issue` | Add an issue found during simulation. |
| `add_recommendation` | `recommendation` | Add a recommendation for improvement. |
| `grade_to_score` | `grade` | Convert letter grade to numeric score. |
| `run_command` | `cmd, cwd, capture_output` | Run a command and return (returncode, stdout, stderr). |
| `stage_1_signup_onboarding` | `` | Stage 1: Simulate signup and onboarding experience. |
| `stage_2_cli_experience` | `` | Stage 2: Test CLI experience and help text. |
| `stage_3_project_creation` | `` | Stage 3: Simulate project creation with GSD. |
| `enhance_user_prompt` | `user_prompt` | Convert basic user prompt to enhanced requirements. |
| `generate_gsd_artifacts` | `user_prompt, enhanced_prompt` | Generate realistic GSD artifacts for a project. |
| `get_primary_features` | `prompt` | Get primary features based on the user prompt. |
| `get_phase2_tasks` | `prompt` | Get Phase 2 tasks based on the user prompt. |
| `get_core_endpoints_tasks` | `prompt` | Get core API endpoints tasks. |
| `get_autoforge_feature_tasks` | `prompt` | Get AutoForge feature development tasks. |
| `get_framework` | `prompt` | Get recommended framework. |
| `get_database` | `prompt` | Get recommended database. |
| `stage_4_autoforge_activation` | `` | Stage 4: Simulate AutoForge activation and execution. |
| `stage_5_gsd_final_audit` | `` | Stage 5: Simulate GSD final audit of completed project. |
| `stage_6_marketplace_submission` | `` | Stage 6: Simulate marketplace submission process. |
| `stage_7_generate_report` | `` | Stage 7: Generate comprehensive journey report. |
| `calculate_duration` | `` | Calculate simulation duration. |
| `run_simulation` | `` | Run the complete user journey simulation. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main entry point. |

---

## `tools/simulation/user_simulator.py`

Virtual User Simulator for MyWork-AI
Generates realistic test users and simulates their actions

*447 lines*

### class `UserRole`(Enum)

### class `UserProfile`

User profile with all necessary attributes

### class `UserAction`

User action types for simulation

### class `VirtualUserSimulator`

Main simulator for creating and managing virtual users

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `generate_referral_code` | `name` | Generate a referral code based on user name |
| `generate_user` | `role, referred_by` | Generate a single realistic user profile |
| `generate_test_users` | `count` | Generate multiple test users with some referral relationships |
| `simulate_browse_action` | `user_id, product_category` | Simulate user browsing products |
| `simulate_purchase_action` | `user_id, product_id, amount` | Simulate user making a purchase |
| `simulate_list_product_action` | `user_id, product_name, price` | Simulate user listing a product for sale |
| `simulate_refer_friend_action` | `user_id, friend_role` | Simulate user referring a friend |
| `simulate_earn_commission_action` | `user_id, amount, source` | Simulate user earning commission |
| `simulate_random_activity` | `user_id` | Simulate random user activity |
| `get_user_stats` | `` | Get comprehensive user statistics |
| `export_users` | `filename` | Export users to JSON file |
| `display_users_summary` | `` | Display a summary of all users |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main function for testing the user simulator |

---

## `tools/skills/installed/code-review/config.py`

Code Review Skill - Configuration
================================
Configure code review rules and preferences.

*50 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Configure code review settings. |

---

## `tools/skills/installed/code-review/help.py`

Code Review Skill - Help
=======================

*48 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Show code review skill help. |

---

## `tools/skills/installed/code-review/report.py`

Code Review Skill - Report Generator
===================================
Generate detailed code review reports in various formats.

*72 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `generate_report` | `format_type` | Generate code review report. |
| `main` | `` | Main report function. |

---

## `tools/skills/installed/code-review/review.py`

Code Review Skill - Main Review Script
=====================================
Automated code review with quality, security, and best practice analysis.

*257 lines*

### class `CodeReviewer`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `path` |  |
| `review` | `` | Main review function. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main review function. |

---

## `tools/skills/installed/deploy-check/check.py`

Deploy Check Skill - Pre-deployment Checklist
============================================
Comprehensive deployment readiness validation.

*383 lines*

### class `DeploymentChecker`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `environment` |  |
| `run_checks` | `` | Run all deployment checks. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main deployment check function. |

---

## `tools/skills/installed/deploy-check/config.py`

Deploy Check Skill - Configuration
=================================
Configure deployment checklist rules and environment settings.

*71 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Configure deployment check settings. |

---

## `tools/skills/installed/deploy-check/help.py`

Deploy Check Skill - Help
========================

*64 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Show deploy check skill help. |

---

## `tools/skills/installed/deploy-check/report.py`

Deploy Check Skill - Report Generator
====================================

*87 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `generate_report` | `` | Generate detailed deployment readiness report. |
| `main` | `` | Main report function. |

---

## `tools/skills/installed/doc-generator/api.py`

Doc Generator Skill - API Documentation
======================================
Generate API documentation from code analysis.

*196 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `generate_api_docs` | `format_type` | Generate API documentation in specified format. |
| `generate_openapi_spec` | `docs` | Generate OpenAPI 3.0 specification. |
| `generate_html_docs` | `docs` | Generate HTML API documentation. |
| `generate_markdown_docs` | `docs` | Generate Markdown API documentation. |
| `main` | `` | Main API documentation function. |

---

## `tools/skills/installed/doc-generator/generate.py`

Doc Generator Skill - Main Generator
===================================
Auto-generate documentation from code analysis.

*400 lines*

### class `DocumentationGenerator`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `path` |  |
| `generate` | `doc_type` | Generate documentation of specified type. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main documentation generation function. |

---

## `tools/skills/installed/doc-generator/help.py`

Doc Generator Skill - Help
=========================

*74 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Show doc generator skill help. |

---

## `tools/skills/installed/doc-generator/inline.py`

Doc Generator Skill - Inline Documentation
==========================================
Generate inline code documentation and docstrings.

*219 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `generate_inline_docs` | `path` | Generate inline documentation for Python files. |
| `main` | `` | Main inline documentation function. |

---

## `tools/skills/installed/doc-generator/readme.py`

Doc Generator Skill - README Generator
=====================================
Auto-generate or update README.md from project analysis.

*267 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `generate_readme` | `` | Generate comprehensive README.md from project analysis. |
| `main` | `` | Main README generation function. |

---

## `tools/skills/installed/security-scan/baseline.py`

Security Scan Skill - Baseline Management
========================================

*39 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Update security baseline. |

---

## `tools/skills/installed/security-scan/diff.py`

Security Scan Skill - Diff Scanner  
=================================
Show only new security issues since last baseline.

*48 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Show security diff since baseline. |

---

## `tools/skills/installed/security-scan/help.py`

Security Scan Skill - Help
=========================

*54 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Show security scan skill help. |

---

## `tools/skills/installed/security-scan/report.py`

Security Scan Skill - Report Generator
=====================================

*92 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `generate_report` | `format_type` | Generate security report in specified format. |
| `main` | `` | Main report function. |

---

## `tools/skills/installed/security-scan/scan.py`

Security Scan Skill - Main Scanner
=================================
Advanced security scanning that wraps the existing MyWork-AI security scanner.

*302 lines*

### class `SecurityScanner`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `path` |  |
| `scan` | `` | Perform comprehensive security scan. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | Main scan function. |

---

## `tools/skills/skill_manager.py`

MyWork-AI Agent Skills Manager
============================
Inspired by Anthropic/OpenAI Agent Skills standard

Manages skills discovery, installation, and execution.
Skills are folder-based with SKILL.md manifest + scripts.

Usage:
    mw skills list               # List installed skills
    mw skills install <url>      # Install skill from GitHub URL
    mw skills create <name>      # Scaffold a new skill
    mw skills remove <name>      # Remove a skill
    mw skills run <name> <cmd>   # Run skill command
    mw skills info <name>        # Show skill information

*547 lines*

### class `SkillManager`

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` | Initialize the Skills Manager. |
| `list_skills` | `` | List all installed skills with metadata. |
| `install_skill` | `url, name` | Install a skill from GitHub URL. |
| `create_skill` | `name` | Scaffold a new skill with template structure. |
| `remove_skill` | `name` | Remove an installed skill. |
| `run_skill_command` | `skill_name, command, args` | Run a specific command from a skill. |
| `show_skill_info` | `name` | Show detailed information about a skill. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `main` | `` | CLI interface for skill manager. |

---

## `tools/smoke_test_ai_dashboard.py`

*102 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `fetch` | `url, expect_json` |  |
| `assert_ok` | `label, url, expect_json` |  |
| `main` | `` |  |

---

## `tools/smoke_test_marketplace.py`

*118 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `fetch` | `url, expect_json` |  |
| `assert_ok` | `label, url, expect_json` |  |
| `main` | `` |  |

---

## `tools/smoke_test_task_tracker.py`

*89 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `fetch` | `url, expect_json` |  |
| `assert_ok` | `label, url, expect_json` |  |
| `main` | `` |  |

---

## `tools/switch_llm_provider.py`

LLM Provider Switcher for Autocoder
Switches between configured LLM providers in Autocoder's .env file.

Usage:
    python switch_llm_provider.py [provider]

Providers:
    zai       - Z.ai GLM-4.7 (cost-effective, default)
    claude    - Native Claude (highest quality)
    openrouter - OpenRouter (100+ models, built-in fallback)
    groq      - Groq (ultra-fast)

Example:
    python switch_llm_provider.py openrouter

*262 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `load_env_file` | `env_path` | Load environment variables from a .env file. |
| `get_env_key` | `key, default` | Get API key from environment. |
| `read_env` | `` | Read the current .env file. |
| `write_env` | `content` | Write the .env file. |
| `get_current_provider` | `content` | Detect current active provider. |
| `resolve_env_vars` | `vars_dict` | Resolve ${VAR_NAME} placeholders with actual environment values. |
| `switch_provider` | `target` | Switch to the target provider. |
| `list_providers` | `` | List all available providers and current status. |
| `main` | `` |  |

---

## `tools/test_auto_linting.py`

Test Script for Auto-Linting Agent
Verifies that the agent works correctly with different file types and scenarios.

*441 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `create_test_files` | `test_dir` | Create test files with linting issues |
| `test_agent_import` | `` | Test that the agent can be imported successfully |
| `test_config_creation` | `` | Test configuration creation and validation |
| `test_file_type_detection` | `` | Test file type detection and tool selection |
| `test_ignore_patterns` | `` | Test file ignoring functionality |
| `test_markdown_linting` | `` | Test markdown linting functionality |
| `test_directory_scanning` | `` | Test directory scanning functionality |
| `test_results_saving` | `` | Test results saving functionality |
| `test_cli_integration` | `` | Test CLI integration |
| `main` | `` | Run all tests |

---

## `tools/test_brain_semantic.py`

Tests for Brain Semantic Search ‚Äî Phase 9.

*192 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `test` | `name` |  |

---

## `tools/test_brain_webhook.py`

Test script to verify Brain webhook integration with Task Tracker.
This simulates the webhook payload that Task Tracker sends.

*96 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `test_brain_webhook` | `webhook_url, allow_prod` | Test the Brain ingestion endpoint. |

---

## `tools/test_credits_ledger.py`

Tests for credits_ledger.py ‚Äî Phase 8 Payment System.

*171 lines*

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `make_ledger` | `tmp` | Create a ledger in a temp dir. |
| `test_add_credits` | `` |  |
| `test_spend_credits` | `` |  |
| `test_insufficient_credits` | `` |  |
| `test_escrow_flow` | `` |  |
| `test_refund` | `` |  |
| `test_reconcile` | `` |  |
| `test_transaction_history` | `` |  |
| `test_stats` | `` |  |
| `test_checksum_integrity` | `` |  |
| `test_bonus_credits` | `` |  |

---

## `tools/workflow_engine.py`

Workflow Engine
===============
Execute multi-step workflows defined in YAML.

Usage:
    python3 workflow_engine.py <workflow-file> [options]
    python3 workflow_engine.py --list
    python3 workflow_engine.py --help

Options:
    --dry-run           Show what would be executed without running
    --step <n>          Start from step number n
    --stop-on-error     Stop execution on first error (default: continue)
    --parallel          Run independent steps in parallel
    --vars <file>       Load variables from JSON file
    --var key=value     Set variable (can be used multiple times)
    --list              List available workflows
    --help              Show this help

Workflow Format:
    name: "Deploy Pipeline"
    description: "Deploy application to production"
    variables:
      PROJECT_NAME: "my-app"
      ENVIRONMENT: "production"
    
    steps:
      - name: "Lint Code"
        run: "mw lint scan"
        working_directory: "."
        continue_on_error: false
        
      - name: "Run Tests"
        run: "mw test"
        condition: "${ENVIRONMENT} != 'development'"
        
      - name: "Build Application"
        run: "mw build"
        depends_on: ["Lint Code", "Run Tests"]
        
      - name: "Deploy"
        run: "mw deploy --env ${ENVIRONMENT}"
        depends_on: ["Build Application"]

Examples:
    python3 workflow_engine.py deploy.yaml
    python3 workflow_engine.py ci-pipeline.yaml --dry-run
    python3 workflow_engine.py deploy.yaml --var ENVIRONMENT=staging
    python3 workflow_engine.py build.yaml --step 3 --parallel

*708 lines*

### class `Colors`

### class `WorkflowStep`

Represents a single workflow step.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `data, step_index` |  |
| `get_duration` | `` | Get step execution duration in seconds. |

### class `WorkflowEngine`

Execute multi-step workflows.

| Method | Args | Description |
|--------|------|-------------|
| `__init__` | `` |  |
| `load_workflow` | `workflow_path` | Load workflow from YAML file. |
| `substitute_variables` | `text, variables` | Substitute variables in text using ${VAR} syntax. |
| `evaluate_condition` | `condition, variables` | Evaluate a simple condition expression. |
| `build_dependency_graph` | `steps` | Build dependency graph for parallel execution. |
| `topological_sort` | `steps` | Return steps grouped by execution level for parallel execution. |
| `execute_step` | `step, variables, dry_run` | Execute a single workflow step. |
| `execute_workflow` | `workflow_path, dry_run, start_step, stop_on_error, parallel` | Execute a complete workflow. |
| `save_execution_report` | `workflow_path, steps, variables, success, dry_run` | Save workflow execution report. |
| `list_workflows` | `` | List available workflows. |

### Functions

| Function | Args | Description |
|----------|------|-------------|
| `color` | `text, color_code` | Apply color to text. |
| `create_sample_workflows` | `` | Create sample workflow files. |
| `main` | `` | Main entry point. |

---

